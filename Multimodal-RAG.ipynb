{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tU-6Y502tY-_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "06cbeb6e-a7e0-43d0-a2e0-0acafdcfac94"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nData Collection and Pre-processing\\n  1. Dataset used - https://ocr-vqa.github.io/\\n  2. Steps Followed:\\n    2.1 Data Loading\\n    2.2 Text Extraction from Images   - OCR to extract text from images\\n    2.3 Image Summarization           - To generate a brief summary or caption for the images\\n    2.4 QA Pairs and MCQ Generation   - Format the extracted text and summaries into QA pairs\\n    2.5 Data Structuring              - To a format that can be easily integrated into a MuRAG pipeline\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "'''\n",
        "Data Collection and Pre-processing\n",
        "  1. Dataset used - https://ocr-vqa.github.io/\n",
        "  2. Steps Followed:\n",
        "    2.1 Data Loading\n",
        "    2.2 Text Extraction from Images   - OCR to extract text from images\n",
        "    2.3 Image Summarization           - To generate a brief summary or caption for the images\n",
        "    2.4 QA Pairs and MCQ Generation   - Format the extracted text and summaries into QA pairs\n",
        "    2.5 Data Structuring              - To a format that can be easily integrated into a MuRAG pipeline\n",
        "'''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "txZLaD2GOkQb"
      },
      "source": [
        "**1. Data Collection and Pre-processing**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get install tesseract-ocr"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9bSOP8b6OBTs",
        "outputId": "54ef0b61-8da0-4fa1-a195-1bef7d7d299e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:OCR failed for processed_images/1492621110.jpg: tesseract is not installed or it's not in your PATH. See README file for more information.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:OCR failed for processed_images/761188274.jpg: tesseract is not installed or it's not in your PATH. See README file for more information.\n",
            "WARNING:__main__:OCR failed for processed_images/1449461573.jpg: tesseract is not installed or it's not in your PATH. See README file for more information.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The following additional packages will be installed:\n",
            "  tesseract-ocr-eng tesseract-ocr-osd\n",
            "The following NEW packages will be installed:\n",
            "  tesseract-ocr tesseract-ocr-eng tesseract-ocr-osd\n",
            "0 upgraded, 3 newly installed, 0 to remove and 49 not upgraded.\n",
            "Need to get 4,816 kB of archives.\n",
            "After this operation, 15.6 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy/universe amd64 tesseract-ocr-eng all 1:4.00~git30-7274cfa-1.1 [1,591 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy/universe amd64 tesseract-ocr-osd all 1:4.00~git30-7274cfa-1.1 [2,990 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu jammy/universe amd64 tesseract-ocr amd64 4.1.1-2.1build1 [236 kB]\n",
            "Fetched 4,816 kB in 1s (8,119 kB/s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "WARNING:__main__:OCR failed for processed_images/1452142068.jpg: tesseract is not installed or it's not in your PATH. See README file for more information.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Selecting previously unselected package tesseract-ocr-eng.\n",
            "(Reading database ... 123629 files and directories currently installed.)\n",
            "Preparing to unpack .../tesseract-ocr-eng_1%3a4.00~git30-7274cfa-1.1_all.deb ...\n",
            "Unpacking tesseract-ocr-eng (1:4.00~git30-7274cfa-1.1) ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:OCR failed for processed_images/B00O80WC7C.jpg: tesseract is not installed or it's not in your PATH. See README file for more information.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Selecting previously unselected package tesseract-ocr-osd.\n",
            "Preparing to unpack .../tesseract-ocr-osd_1%3a4.00~git30-7274cfa-1.1_all.deb ...\n",
            "Unpacking tesseract-ocr-osd (1:4.00~git30-7274cfa-1.1) ...\n",
            "Selecting previously unselected package tesseract-ocr.\n",
            "Preparing to unpack .../tesseract-ocr_4.1.1-2.1build1_amd64.deb ...\n",
            "Unpacking tesseract-ocr (4.1.1-2.1build1) ...\n",
            "Setting up tesseract-ocr-eng (1:4.00~git30-7274cfa-1.1) ...\n",
            "Setting up tesseract-ocr-osd (1:4.00~git30-7274cfa-1.1) ...\n",
            "Setting up tesseract-ocr (4.1.1-2.1build1) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hLvsWwHftl6e",
        "outputId": "7a2da1d1-7517-4d05-fafb-8bd3a6e58f5c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n",
            "WARNING:__main__:OCR failed for processed_images/B00O80WC6I.jpg: tesseract is not installed or it's not in your PATH. See README file for more information.\n",
            "WARNING:__main__:OCR failed for processed_images/761183272.jpg: tesseract is not installed or it's not in your PATH. See README file for more information.\n",
            "WARNING:__main__:OCR failed for processed_images/1623439671.jpg: tesseract is not installed or it's not in your PATH. See README file for more information.\n",
            "WARNING:__main__:OCR failed for processed_images/761182187.jpg: tesseract is not installed or it's not in your PATH. See README file for more information.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "Processing items:   0%|          | 0/207572 [00:00<?, ?it/s]"
          ]
        }
      ],
      "source": [
        "import json\n",
        "import pandas as pd\n",
        "import requests\n",
        "from PIL import Image\n",
        "from io import BytesIO\n",
        "import pytesseract\n",
        "from transformers import pipeline\n",
        "from tqdm import tqdm\n",
        "import os\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "import logging\n",
        "import numpy as np\n",
        "\n",
        "class MuRAGPreprocessor:\n",
        "    def __init__(self, json_path, image_save_dir='processed_images', batch_size=32):\n",
        "        \"\"\"\n",
        "        Initialize the MuRAG preprocessor\n",
        "\n",
        "        Args:\n",
        "            json_path (str): Path to the OCR-VQA dataset JSON file\n",
        "            image_save_dir (str): Directory to save downloaded images\n",
        "            batch_size (int): Batch size for processing\n",
        "        \"\"\"\n",
        "        self.json_path = json_path\n",
        "        self.image_save_dir = image_save_dir\n",
        "        self.batch_size = batch_size\n",
        "        self.image_captioner = pipeline(\"image-to-text\", model=\"Salesforce/blip-image-captioning-base\")\n",
        "        logging.basicConfig(\n",
        "            level=logging.INFO,\n",
        "            format='%(asctime)s - %(levelname)s - %(message)s'\n",
        "        )\n",
        "        self.logger = logging.getLogger(__name__)\n",
        "        os.makedirs(image_save_dir, exist_ok=True)\n",
        "\n",
        "    def load_data(self):\n",
        "        \"\"\"Load and perform initial parsing of the dataset\"\"\"\n",
        "        try:\n",
        "            with open(self.json_path, 'r') as f:\n",
        "                self.raw_data = json.load(f)\n",
        "            self.logger.info(f\"Successfully loaded {len(self.raw_data)} items from dataset\")\n",
        "            return True\n",
        "        except Exception as e:\n",
        "            self.logger.error(f\"Error loading data: {str(e)}\")\n",
        "            return False\n",
        "\n",
        "    def download_image(self, image_id, url):\n",
        "        \"\"\"Download and save an image from URL\"\"\"\n",
        "        try:\n",
        "            response = requests.get(url, timeout=10)\n",
        "            if response.status_code == 200:\n",
        "                img_path = os.path.join(self.image_save_dir, f\"{image_id}.jpg\")\n",
        "                Image.open(BytesIO(response.content)).save(img_path)\n",
        "                return img_path\n",
        "            return None\n",
        "        except Exception as e:\n",
        "            self.logger.warning(f\"Failed to download image {image_id}: {str(e)}\")\n",
        "            return None\n",
        "\n",
        "    def extract_text_from_image(self, image_path):\n",
        "        \"\"\"Extract text from image using OCR\"\"\"\n",
        "        try:\n",
        "            if image_path and os.path.exists(image_path):\n",
        "                img = Image.open(image_path)\n",
        "                text = pytesseract.image_to_string(img)\n",
        "                return text.strip()\n",
        "            return \"\"\n",
        "        except Exception as e:\n",
        "            self.logger.warning(f\"OCR failed for {image_path}: {str(e)}\")\n",
        "            return \"\"\n",
        "\n",
        "    def generate_image_summary(self, image_path):\n",
        "        \"\"\"Generate a caption/summary for the image\"\"\"\n",
        "        try:\n",
        "            if image_path and os.path.exists(image_path):\n",
        "                image = Image.open(image_path)\n",
        "                caption = self.image_captioner(image)[0]['generated_text']\n",
        "                return caption\n",
        "            return \"\"\n",
        "        except Exception as e:\n",
        "            self.logger.warning(f\"Caption generation failed for {image_path}: {str(e)}\")\n",
        "            return \"\"\n",
        "\n",
        "    def generate_mcq(self, correct_answer, context):\n",
        "        \"\"\"Generate MCQ options including the correct answer\"\"\"\n",
        "        options = [correct_answer]\n",
        "        other_answers = [\n",
        "            ans for ans in set(context['answers'])\n",
        "            if ans != correct_answer\n",
        "        ]\n",
        "        options.extend(np.random.choice(other_answers, min(3, len(other_answers)), replace=False))\n",
        "        while len(options) < 4:\n",
        "            options.append(f\"None of the above {len(options)}\")\n",
        "        return options\n",
        "\n",
        "    def process_item(self, item_id, item_data):\n",
        "        \"\"\"Process a single dataset item\"\"\"\n",
        "        try:\n",
        "            image_path = self.download_image(item_id, item_data['imageURL'])\n",
        "            if not image_path:\n",
        "                return None\n",
        "            ocr_text = self.extract_text_from_image(image_path)\n",
        "            image_summary = self.generate_image_summary(image_path)\n",
        "            qa_pairs = []\n",
        "            for q, a in zip(item_data['questions'], item_data['answers']):\n",
        "                qa_pair = {\n",
        "                    'question': q,\n",
        "                    'answer': a,\n",
        "                    'options': self.generate_mcq(a, item_data),\n",
        "                    'context': {\n",
        "                        'ocr_text': ocr_text,\n",
        "                        'image_summary': image_summary,\n",
        "                        'title': item_data.get('title', ''),\n",
        "                        'author': item_data.get('authorName', ''),\n",
        "                        'genre': item_data.get('genre', ''),\n",
        "                        'image_path': image_path\n",
        "                    }\n",
        "                }\n",
        "                qa_pairs.append(qa_pair)\n",
        "\n",
        "            return qa_pairs\n",
        "\n",
        "        except Exception as e:\n",
        "            self.logger.error(f\"Error processing item {item_id}: {str(e)}\")\n",
        "            return None\n",
        "\n",
        "    def process_dataset(self):\n",
        "        \"\"\"Process the entire dataset\"\"\"\n",
        "        processed_data = []\n",
        "\n",
        "        with ThreadPoolExecutor(max_workers=4) as executor:\n",
        "            future_to_id = {\n",
        "                executor.submit(self.process_item, item_id, item_data): item_id\n",
        "                for item_id, item_data in self.raw_data.items()\n",
        "            }\n",
        "\n",
        "            for future in tqdm(future_to_id, desc=\"Processing items\"):\n",
        "                item_id = future_to_id[future]\n",
        "                try:\n",
        "                    result = future.result()\n",
        "                    if result:\n",
        "                        processed_data.extend(result)\n",
        "                except Exception as e:\n",
        "                    self.logger.error(f\"Failed to process item {item_id}: {str(e)}\")\n",
        "        self.save_processed_data(processed_data)\n",
        "        return processed_data\n",
        "\n",
        "    def save_processed_data(self, processed_data):\n",
        "        \"\"\"Save the processed dataset\"\"\"\n",
        "        try:\n",
        "            with open('processed_murag_data.json', 'w') as f:\n",
        "                json.dump(processed_data, f)\n",
        "            df = pd.DataFrame(processed_data)\n",
        "            df.to_csv('processed_murag_data.csv', index=False)\n",
        "\n",
        "            self.logger.info(f\"Successfully saved {len(processed_data)} processed items\")\n",
        "        except Exception as e:\n",
        "            self.logger.error(f\"Error saving processed data: {str(e)}\")\n",
        "\n",
        "def main():\n",
        "    preprocessor = MuRAGPreprocessor(\n",
        "        json_path='/content/dataset.json',\n",
        "        image_save_dir='processed_images',\n",
        "        batch_size=32\n",
        "    )\n",
        "\n",
        "    if preprocessor.load_data():\n",
        "        processed_data = preprocessor.process_dataset()\n",
        "        print(f\"Successfully processed {len(processed_data)} QA pairs\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZbKoQyCzPYGg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1c963bb9-c542-4321-f03f-508f58a8b889"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n",
            "Processing items:   0%|          | 0/50 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "Processing items:   2%|▏         | 1/50 [01:12<58:56, 72.17s/it]/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "Processing items:   6%|▌         | 3/50 [01:36<21:34, 27.54s/it]/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "Processing items:  12%|█▏        | 6/50 [02:06<11:22, 15.52s/it]/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "Processing items:  16%|█▌        | 8/50 [02:28<09:30, 13.59s/it]/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "Processing items:  18%|█▊        | 9/50 [03:26<16:25, 24.05s/it]/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "Processing items:  24%|██▍       | 12/50 [03:46<09:43, 15.36s/it]/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "Processing items:  26%|██▌       | 13/50 [03:48<07:52, 12.78s/it]/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "Processing items:  28%|██▊       | 14/50 [03:56<06:58, 11.64s/it]/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "Processing items:  30%|███       | 15/50 [04:10<07:07, 12.22s/it]/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "Processing items:  32%|███▏      | 16/50 [04:30<08:06, 14.30s/it]/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "Processing items:  38%|███▊      | 19/50 [04:52<05:09, 10.00s/it]/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "Processing items:  40%|████      | 20/50 [06:00<13:23, 26.77s/it]/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "Processing items:  44%|████▍     | 22/50 [06:10<07:52, 16.88s/it]/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "Processing items:  50%|█████     | 25/50 [06:45<05:48, 13.93s/it]/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "Processing items:  52%|█████▏    | 26/50 [07:05<06:04, 15.20s/it]/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "Processing items:  54%|█████▍    | 27/50 [07:40<07:47, 20.35s/it]/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "Processing items:  60%|██████    | 30/50 [08:06<04:45, 14.26s/it]/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "Processing items:  62%|██████▏   | 31/50 [08:54<06:38, 20.98s/it]/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "Processing items:  68%|██████▊   | 34/50 [09:32<04:34, 17.16s/it]/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "Processing items:  72%|███████▏  | 36/50 [10:15<04:18, 18.44s/it]/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "Processing items:  78%|███████▊  | 39/50 [10:43<02:42, 14.80s/it]/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "Processing items:  84%|████████▍ | 42/50 [11:22<01:46, 13.37s/it]/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "Processing items:  86%|████████▌ | 43/50 [12:14<02:37, 22.43s/it]/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "Processing items:  94%|█████████▍| 47/50 [12:58<00:43, 14.38s/it]/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "Processing items:  98%|█████████▊| 49/50 [13:35<00:14, 14.80s/it]/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "Processing items: 100%|██████████| 50/50 [13:51<00:00, 16.63s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully processed 267 QA pairs\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "import pandas as pd\n",
        "import requests\n",
        "from PIL import Image\n",
        "from io import BytesIO\n",
        "import pytesseract\n",
        "from transformers import pipeline\n",
        "from tqdm import tqdm\n",
        "import os\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "import logging\n",
        "import numpy as np\n",
        "\n",
        "class MuRAGPreprocessor:\n",
        "    def __init__(self, json_path, image_save_dir='processed_images', batch_size=32, max_items=None):\n",
        "        \"\"\"\n",
        "        Initialize the MuRAG preprocessor\n",
        "\n",
        "        Args:\n",
        "            json_path (str): Path to the OCR-VQA dataset JSON file\n",
        "            image_save_dir (str): Directory to save downloaded images\n",
        "            batch_size (int): Batch size for processing\n",
        "            max_items (int): Maximum number of items to process (default is None for all)\n",
        "        \"\"\"\n",
        "        self.json_path = json_path\n",
        "        self.image_save_dir = image_save_dir\n",
        "        self.batch_size = batch_size\n",
        "        self.max_items = max_items\n",
        "        self.image_captioner = pipeline(\"image-to-text\", model=\"Salesforce/blip-image-captioning-base\")\n",
        "        logging.basicConfig(\n",
        "            level=logging.INFO,\n",
        "            format='%(asctime)s - %(levelname)s - %(message)s'\n",
        "        )\n",
        "        self.logger = logging.getLogger(__name__)\n",
        "        os.makedirs(image_save_dir, exist_ok=True)\n",
        "\n",
        "    def load_data(self):\n",
        "        \"\"\"Load and perform initial parsing of the dataset\"\"\"\n",
        "        try:\n",
        "            with open(self.json_path, 'r') as f:\n",
        "                self.raw_data = json.load(f)\n",
        "            if self.max_items:\n",
        "                self.raw_data = dict(list(self.raw_data.items())[:self.max_items])\n",
        "\n",
        "            self.logger.info(f\"Successfully loaded {len(self.raw_data)} items from dataset\")\n",
        "            return True\n",
        "        except Exception as e:\n",
        "            self.logger.error(f\"Error loading data: {str(e)}\")\n",
        "            return False\n",
        "\n",
        "    def download_image(self, image_id, url):\n",
        "        \"\"\"Download and save an image from URL\"\"\"\n",
        "        try:\n",
        "            response = requests.get(url, timeout=10)\n",
        "            if response.status_code == 200:\n",
        "                img_path = os.path.join(self.image_save_dir, f\"{image_id}.jpg\")\n",
        "                Image.open(BytesIO(response.content)).save(img_path)\n",
        "                return img_path\n",
        "            return None\n",
        "        except Exception as e:\n",
        "            self.logger.warning(f\"Failed to download image {image_id}: {str(e)}\")\n",
        "            return None\n",
        "\n",
        "    def extract_text_from_image(self, image_path):\n",
        "        \"\"\"Extract text from image using OCR\"\"\"\n",
        "        try:\n",
        "            if image_path and os.path.exists(image_path):\n",
        "                img = Image.open(image_path)\n",
        "                text = pytesseract.image_to_string(img)\n",
        "                return text.strip()\n",
        "            return \"\"\n",
        "        except Exception as e:\n",
        "            self.logger.warning(f\"OCR failed for {image_path}: {str(e)}\")\n",
        "            return \"\"\n",
        "\n",
        "    def generate_image_summary(self, image_path):\n",
        "        \"\"\"Generate a caption/summary for the image\"\"\"\n",
        "        try:\n",
        "            if image_path and os.path.exists(image_path):\n",
        "                image = Image.open(image_path)\n",
        "                caption = self.image_captioner(image)[0]['generated_text']\n",
        "                return caption\n",
        "            return \"\"\n",
        "        except Exception as e:\n",
        "            self.logger.warning(f\"Caption generation failed for {image_path}: {str(e)}\")\n",
        "            return \"\"\n",
        "\n",
        "    def generate_mcq(self, correct_answer, context):\n",
        "        \"\"\"Generate MCQ options including the correct answer\"\"\"\n",
        "        options = [correct_answer]\n",
        "        other_answers = [\n",
        "            ans for ans in set(context['answers'])\n",
        "            if ans != correct_answer\n",
        "        ]\n",
        "        options.extend(np.random.choice(other_answers, min(3, len(other_answers)), replace=False))\n",
        "        while len(options) < 4:\n",
        "            options.append(f\"None of the above {len(options)}\")\n",
        "        return options\n",
        "\n",
        "    def process_item(self, item_id, item_data):\n",
        "        \"\"\"Process a single dataset item\"\"\"\n",
        "        try:\n",
        "            image_path = self.download_image(item_id, item_data['imageURL'])\n",
        "            if not image_path:\n",
        "                return None\n",
        "            ocr_text = self.extract_text_from_image(image_path)\n",
        "            image_summary = self.generate_image_summary(image_path)\n",
        "            qa_pairs = []\n",
        "            for q, a in zip(item_data['questions'], item_data['answers']):\n",
        "                qa_pair = {\n",
        "                    'question': q,\n",
        "                    'answer': a,\n",
        "                    'options': self.generate_mcq(a, item_data),\n",
        "                    'context': {\n",
        "                        'ocr_text': ocr_text,\n",
        "                        'image_summary': image_summary,\n",
        "                        'title': item_data.get('title', ''),\n",
        "                        'author': item_data.get('authorName', ''),\n",
        "                        'genre': item_data.get('genre', ''),\n",
        "                        'image_path': image_path\n",
        "                    }\n",
        "                }\n",
        "                qa_pairs.append(qa_pair)\n",
        "\n",
        "            return qa_pairs\n",
        "\n",
        "        except Exception as e:\n",
        "            self.logger.error(f\"Error processing item {item_id}: {str(e)}\")\n",
        "            return None\n",
        "\n",
        "    def process_dataset(self):\n",
        "        \"\"\"Process the entire dataset\"\"\"\n",
        "        processed_data = []\n",
        "\n",
        "        with ThreadPoolExecutor(max_workers=4) as executor:\n",
        "            future_to_id = {\n",
        "                executor.submit(self.process_item, item_id, item_data): item_id\n",
        "                for item_id, item_data in self.raw_data.items()\n",
        "            }\n",
        "\n",
        "            for future in tqdm(future_to_id, desc=\"Processing items\"):\n",
        "                item_id = future_to_id[future]\n",
        "                try:\n",
        "                    result = future.result()\n",
        "                    if result:\n",
        "                        processed_data.extend(result)\n",
        "                except Exception as e:\n",
        "                    self.logger.error(f\"Failed to process item {item_id}: {str(e)}\")\n",
        "        self.save_processed_data(processed_data)\n",
        "        return processed_data\n",
        "\n",
        "    def save_processed_data(self, processed_data):\n",
        "        \"\"\"Save the processed dataset\"\"\"\n",
        "        try:\n",
        "            with open('processed_murag_data.json', 'w') as f:\n",
        "                json.dump(processed_data, f)\n",
        "            df = pd.DataFrame(processed_data)\n",
        "            df.to_csv('processed_murag_data.csv', index=False)\n",
        "\n",
        "            self.logger.info(f\"Successfully saved {len(processed_data)} processed items\")\n",
        "        except Exception as e:\n",
        "            self.logger.error(f\"Error saving processed data: {str(e)}\")\n",
        "\n",
        "def main():\n",
        "    preprocessor = MuRAGPreprocessor(\n",
        "        json_path='/content/dataset.json',\n",
        "        image_save_dir='processed_images2',\n",
        "        batch_size=32,\n",
        "        max_items=50\n",
        "    )\n",
        "\n",
        "    if preprocessor.load_data():\n",
        "        processed_data = preprocessor.process_dataset()\n",
        "        print(f\"Successfully processed {len(processed_data)} QA pairs\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch torchvision transformers datasets faiss-cpu\n"
      ],
      "metadata": {
        "id": "J_wwjeKRQA58"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "import pandas as pd\n",
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "class MuRAGDataset(Dataset):\n",
        "    def __init__(self, data_file, image_transform=None):\n",
        "        self.data = pd.read_json(data_file)  # Assuming processed data is in JSON format\n",
        "        self.image_transform = image_transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = self.data.iloc[idx]\n",
        "        image_path = item['context']['image_path']\n",
        "        image = Image.open(image_path)\n",
        "\n",
        "        if self.image_transform:\n",
        "            image = self.image_transform(image)\n",
        "\n",
        "        return {\n",
        "            'text': item['question'],\n",
        "            'image': image,\n",
        "            'label': item['answer']\n",
        "        }\n",
        "\n",
        "# Define image transformations\n",
        "image_transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),  # Resize for the model\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "# Create dataset and dataloader\n",
        "dataset = MuRAGDataset('processed_murag_data.json', image_transform=image_transform)\n",
        "dataloader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
        "\n",
        "# Collect all unique labels from your dataset\n",
        "unique_labels = set()\n",
        "for idx in range(len(dataset)):\n",
        "    unique_labels.add(dataset[idx]['label'])\n",
        "\n",
        "# Print unique labels to verify\n",
        "print(\"Unique labels in dataset:\", unique_labels)\n",
        "\n",
        "# Define your label-to-index mapping based on the unique labels\n",
        "label_to_index = {label: idx for idx, label in enumerate(unique_labels)}\n",
        "print(\"Label to index mapping:\", label_to_index)\n"
      ],
      "metadata": {
        "id": "XusACdBpQBXO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9a54de73-9352-4b34-efda-08be6eb2d6d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unique labels in dataset: {'Amy Knapp', 'Grumpy Cat 2016 Wall Calendar', 'No', 'Workman Publishing', 'Audubon Engagement Calendar 2016', '2016 Almond Blossoms Weekly Planner (16-Month Engagement Calendar, Diary)', 'Amc', 'Ansel Adams 2016 Wall Calendar', 'MAXINE  Year-In-A-Box Calendar (2016)', '2015', 'Audubon Nature Wall Calendar 2016', 'Mary Engelbreit 2016 Deluxe Wall Calendar: Never Give Up', 'Linda Dannenberg', \"Llewellyn's 2016 Witches' Datebook\", 'Mary Engelbreit 2016 Monthly Pocket Planner: Just Being ME!', 'Doug the Pug 2016 Wall Calendar', 'Old FarmerEEs Almanac', 'Anne Taintor 2016 Wall Calendar', 'Chihuly 2016 Wall Calendar', 'Nintendo', 'Barbara Ardinger', \"Llewellyn's 2016 Witches' Calendar\", 'Anne Taintor', 'Dale Chihuly', 'Sierra Club Engagement Calendar 2016', '2016 National Park Foundation Wall Calendar', \"Mom's Family Wall Calendar 2016\", 'Today Is Going to Be a Great Day! Color Page-A-Day Calendar 2016', 'Moleskine 2015-2016 Weekly Notebook, 18M, Large, Black, Soft Cover (5 x 8.25)', 'Moleskine', 'Thomas Kinkade: The Disney Dreams Collection 2016 Wall Calendar', '365 New Words-A-Year Page-A-Day Calendar 2016', 'Pusheen the Cat 2016 Wall Calendar', 'Moleskine 2016 Weekly Notebook, 12M, Extra Large, Black, Soft Cover (7.5 x 10)', 'Mary Engelbreit', 'Moleskine 2016 Monthly Notebook, 12M, Extra Large, Black, Soft Cover (7.5 x 10)', 'Day Dream', 'Dog Page-A-Day Gallery Calendar 2016', '2016', '365 Cats Color Page-A-Day Calendar 2016', 'Sierra Club Wilderness Calendar 2016', 'Llewellyn', 'Cat Page-A-Day Gallery Calendar 2016', 'Starz', 'Dilbert 2016 Day-to-Day Calendar', 'The Legend of Zelda 2016 Wall Calendar', 'French Country Diary 2016 Calendar', 'Year-In-A-Box', 'Mary Engelbreit 2016 Day-to-Day Calendar: Enjoy the Joy', 'Audubon Birds Page-A-Day Gallery Calendar 2016', 'Yes', 'Thomas Kinkade', 'Sierra Club', '365 Dogs Color Page-A-Day Calendar 2016', '2016 Amy Knapp Big Grid Wall Calendar: The essential organization and communication tool for the entire family', 'Posh: Coloring 2016 Day-to-Day Calendar: For Fun & Relaxation', 'Moleskine 2016 Weekly Notebook, 12M, Large, Black, Soft Cover (5 x 8.25)', \"The Complete Runner's Day-by-Day Log 2016 Calendar\", 'Thaneeya McArdle', 'National Audubon Society', 'Moleskine 2016 Weekly Notebook, 12M, Pocket, Black, Soft Cover (3.5 x 5.5)', 'Claire Belton', 'Grumpy Cat', 'Calendars', '2016 Susan Branch Wall Calendar', 'Someecards', 'Peter Pauper Press', 'Walking Dead 2016 Wall Calendar', 'Andrews McMeel Publishing LLC', 'George R. R. Martin', 'Posh: Coloring 2015-2016 Large Monthly/Weekly Planning Calendar', 'Once Upon a Time Wall Calendar (2016)', 'Outlander 2016 Wall Calendar', \"The Old Farmer's Almanac 2016 Gardening Calendar\", 'Susan Branch', 'Merriam-Webster', \"Mary Engelbreit 2016 Weekly Planner Calendar: Smile! It's Good For  You\", 'Sandra Boynton', 'Jane Meredith', '2016 Someecards Daily Desktop Calendar', 'Scott Adams', 'A Song of Ice and Fire 2016 Calendar', 'National Parks Foundation', 'Disney Descendants Wall Calendar (2016)', \"Llewellyn's 2016 Astrological Calendar: 83rd Edition of the World's Best Known, Most Trusted Astrology Calendar\", 'Doug the Pug', 'Color Your Year Wall Calendar 2016: Mindful Coloring Through the Seasons', 'Marty Jerome'}\n",
            "Label to index mapping: {'Amy Knapp': 0, 'Grumpy Cat 2016 Wall Calendar': 1, 'No': 2, 'Workman Publishing': 3, 'Audubon Engagement Calendar 2016': 4, '2016 Almond Blossoms Weekly Planner (16-Month Engagement Calendar, Diary)': 5, 'Amc': 6, 'Ansel Adams 2016 Wall Calendar': 7, 'MAXINE  Year-In-A-Box Calendar (2016)': 8, '2015': 9, 'Audubon Nature Wall Calendar 2016': 10, 'Mary Engelbreit 2016 Deluxe Wall Calendar: Never Give Up': 11, 'Linda Dannenberg': 12, \"Llewellyn's 2016 Witches' Datebook\": 13, 'Mary Engelbreit 2016 Monthly Pocket Planner: Just Being ME!': 14, 'Doug the Pug 2016 Wall Calendar': 15, 'Old FarmerEEs Almanac': 16, 'Anne Taintor 2016 Wall Calendar': 17, 'Chihuly 2016 Wall Calendar': 18, 'Nintendo': 19, 'Barbara Ardinger': 20, \"Llewellyn's 2016 Witches' Calendar\": 21, 'Anne Taintor': 22, 'Dale Chihuly': 23, 'Sierra Club Engagement Calendar 2016': 24, '2016 National Park Foundation Wall Calendar': 25, \"Mom's Family Wall Calendar 2016\": 26, 'Today Is Going to Be a Great Day! Color Page-A-Day Calendar 2016': 27, 'Moleskine 2015-2016 Weekly Notebook, 18M, Large, Black, Soft Cover (5 x 8.25)': 28, 'Moleskine': 29, 'Thomas Kinkade: The Disney Dreams Collection 2016 Wall Calendar': 30, '365 New Words-A-Year Page-A-Day Calendar 2016': 31, 'Pusheen the Cat 2016 Wall Calendar': 32, 'Moleskine 2016 Weekly Notebook, 12M, Extra Large, Black, Soft Cover (7.5 x 10)': 33, 'Mary Engelbreit': 34, 'Moleskine 2016 Monthly Notebook, 12M, Extra Large, Black, Soft Cover (7.5 x 10)': 35, 'Day Dream': 36, 'Dog Page-A-Day Gallery Calendar 2016': 37, '2016': 38, '365 Cats Color Page-A-Day Calendar 2016': 39, 'Sierra Club Wilderness Calendar 2016': 40, 'Llewellyn': 41, 'Cat Page-A-Day Gallery Calendar 2016': 42, 'Starz': 43, 'Dilbert 2016 Day-to-Day Calendar': 44, 'The Legend of Zelda 2016 Wall Calendar': 45, 'French Country Diary 2016 Calendar': 46, 'Year-In-A-Box': 47, 'Mary Engelbreit 2016 Day-to-Day Calendar: Enjoy the Joy': 48, 'Audubon Birds Page-A-Day Gallery Calendar 2016': 49, 'Yes': 50, 'Thomas Kinkade': 51, 'Sierra Club': 52, '365 Dogs Color Page-A-Day Calendar 2016': 53, '2016 Amy Knapp Big Grid Wall Calendar: The essential organization and communication tool for the entire family': 54, 'Posh: Coloring 2016 Day-to-Day Calendar: For Fun & Relaxation': 55, 'Moleskine 2016 Weekly Notebook, 12M, Large, Black, Soft Cover (5 x 8.25)': 56, \"The Complete Runner's Day-by-Day Log 2016 Calendar\": 57, 'Thaneeya McArdle': 58, 'National Audubon Society': 59, 'Moleskine 2016 Weekly Notebook, 12M, Pocket, Black, Soft Cover (3.5 x 5.5)': 60, 'Claire Belton': 61, 'Grumpy Cat': 62, 'Calendars': 63, '2016 Susan Branch Wall Calendar': 64, 'Someecards': 65, 'Peter Pauper Press': 66, 'Walking Dead 2016 Wall Calendar': 67, 'Andrews McMeel Publishing LLC': 68, 'George R. R. Martin': 69, 'Posh: Coloring 2015-2016 Large Monthly/Weekly Planning Calendar': 70, 'Once Upon a Time Wall Calendar (2016)': 71, 'Outlander 2016 Wall Calendar': 72, \"The Old Farmer's Almanac 2016 Gardening Calendar\": 73, 'Susan Branch': 74, 'Merriam-Webster': 75, \"Mary Engelbreit 2016 Weekly Planner Calendar: Smile! It's Good For  You\": 76, 'Sandra Boynton': 77, 'Jane Meredith': 78, '2016 Someecards Daily Desktop Calendar': 79, 'Scott Adams': 80, 'A Song of Ice and Fire 2016 Calendar': 81, 'National Parks Foundation': 82, 'Disney Descendants Wall Calendar (2016)': 83, \"Llewellyn's 2016 Astrological Calendar: 83rd Edition of the World's Best Known, Most Trusted Astrology Calendar\": 84, 'Doug the Pug': 85, 'Color Your Year Wall Calendar 2016: Mindful Coloring Through the Seasons': 86, 'Marty Jerome': 87}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from transformers import BertModel, BertTokenizer\n",
        "from torchvision import models\n",
        "\n",
        "class MuRAG(nn.Module):\n",
        "    def __init__(self, num_classes):\n",
        "        super(MuRAG, self).__init__()\n",
        "        self.bert = BertModel.from_pretrained(\"bert-base-uncased\")\n",
        "        self.bert_tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "\n",
        "        self.resnet = models.resnet50(pretrained=True)\n",
        "        self.resnet.fc = nn.Identity()  # Remove classification layer\n",
        "\n",
        "        self.fc = nn.Linear(self.bert.config.hidden_size + 2048, num_classes)  # Combine outputs\n",
        "\n",
        "    def forward(self, text, images):\n",
        "        # Tokenize text and get embeddings\n",
        "        text_inputs = self.bert_tokenizer(text, padding=True, truncation=True, return_tensors='pt')\n",
        "        text_outputs = self.bert(**text_inputs)\n",
        "        text_embedding = text_outputs.pooler_output\n",
        "\n",
        "        # Get image embeddings\n",
        "        image_embeddings = self.resnet(images)\n",
        "\n",
        "        # Combine embeddings\n",
        "        combined = torch.cat((text_embedding, image_embeddings), dim=1)\n",
        "        output = self.fc(combined)\n",
        "\n",
        "        return output\n"
      ],
      "metadata": {
        "id": "XEnlKdzCWe_c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "def train(model, dataloader, device, epochs=5):\n",
        "    model.train()\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        total_loss = 0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        for batch in tqdm(dataloader):\n",
        "            text, images, labels = batch['text'], batch['image'].to(device), batch['label']\n",
        "\n",
        "            # Debug: print labels to check values\n",
        "            print(f\"Batch Labels: {labels}\")\n",
        "\n",
        "            # Normalize and map labels to indices\n",
        "            labels = [label.strip() for label in labels]  # Clean labels\n",
        "            labels = torch.tensor([label_to_index.get(label, -1) for label in labels]).to(device)\n",
        "\n",
        "            # Debug: print mapped labels to check for invalid values\n",
        "            print(f\"Mapped Labels: {labels}\")\n",
        "\n",
        "            # Filter out invalid labels\n",
        "            valid_mask = labels != -1\n",
        "            if not valid_mask.any():\n",
        "                print(\"Warning: Skipping batch with all invalid labels.\")\n",
        "                continue  # Skip batch with all invalid labels\n",
        "\n",
        "            # Filter batch based on valid labels\n",
        "            text = [t for t, valid in zip(text, valid_mask) if valid]\n",
        "            images = images[valid_mask]\n",
        "            labels = labels[valid_mask]\n",
        "\n",
        "            # Forward pass\n",
        "            outputs = model(text, images)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            # Backward pass\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            total_loss += loss.item()\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "            total += labels.size(0)\n",
        "\n",
        "            print(f\"Epoch [{epoch + 1}/{epochs}], Batch Loss: {loss.item():.4f}\")\n",
        "\n",
        "        epoch_loss = total_loss / len(dataloader)\n",
        "        if total > 0:\n",
        "            accuracy = 100 * correct / total\n",
        "            print(f\"Epoch [{epoch + 1}/{epochs}], Average Loss: {epoch_loss:.4f}, Accuracy: {accuracy:.2f}%\")\n",
        "        else:\n",
        "            print(f\"Epoch [{epoch + 1}/{epochs}], Average Loss: {epoch_loss:.4f}, No valid labels to calculate accuracy.\")\n"
      ],
      "metadata": {
        "id": "8ZGGd5FDWfFn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Device setup\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = MuRAG(num_classes=len(label_to_index)).to(device)\n",
        "\n",
        "# Train the model\n",
        "train(model, dataloader, device)\n"
      ],
      "metadata": {
        "id": "KEudGjyEWfJk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "e203260fc47e49eca3733a57f4e6fd1b",
            "180940aadbc64881809755cc53f1172e",
            "f165a8f17a5144a4b651ca032aa27d71",
            "9e5235714f2d40dea6d45349458ad64d",
            "47af4892314546d1bdaf38154525126f",
            "56bb7b3e8fa142ff8470ca92e4e6c4da",
            "ad87482fd7834e049c8aa4c61a67d2ed",
            "f68c4bec937648958b624bde6bddb97e",
            "bfde078ebee84a54826a9f95955cddb4",
            "3cada9fc296c4fb1b3d7018f8cd09f73",
            "4714cc5be8c44d71b6bcd319e70842b8",
            "44fcedaba19640798539feed184d367a",
            "2e93a603b98544099287da10bc9de01b",
            "bbe56034fdb6400289bd3e9c9ae5a71f",
            "186caa299e6e4562995495d064bef8e1",
            "c094d315277e4d8daea93ee5260b3e74",
            "ad0b2614d7774172823187efa3745cb8",
            "4cd27ca693204d6798bca7a8ac76013c",
            "c318708c6e364d2badb6f7fc109ba6f4",
            "97e87c14ffc142d4b12e431fe33514f4",
            "f3f1536b628d486c8bbf6c84a3e2497c",
            "e60b77666f95412d94ad516d11a08c97",
            "ecc4f94e49b545ea8bc0962019cfb8fa",
            "421718a167b14c3398079b9f542fcee3",
            "b3c9e9a50acb48c18623eb2ebb4b1672",
            "02c95a4c36e54061b54f8b49a7987070",
            "4ee2dce619d0481783ca0296c67b1071",
            "999d96d7964a44259ea82383227e1546",
            "009e08782ade4e90a9d7a3ded4925481",
            "92320eb340ba4ed18bc0c177d0bb1fd8",
            "dada0ecf97ef4865bdd6422842fc8385",
            "973ca71cc43547889c65a681c9ada8de",
            "113983b49f3241d7a0d254893b0560bb",
            "64c6d0307cde4d4890345ce1ac1928c1",
            "40d675faae9c4653b78e23c799fd14db",
            "40b723bb58e14dc68cb3dd0ac1385e2d",
            "ed02039f37524c7f92d67adc1fbb53b1",
            "bd096a5ae334404f8aefea7d92dc1b8d",
            "e00f12b95a554a7cb222f861cd429c50",
            "b0af37fb10484dadbe47ead6cd112fc6",
            "65639109df474af89213b3e012736c92",
            "361d2592c61e4e05b79db432cbabf7f5",
            "6a187c4c5999461a9c653b93c886fb39",
            "a0a77afac2f94af4b68fdebaf3ea4384",
            "4fb22149260b400fb05b5c25052c3436",
            "27388f8bf3a9431f9a3673bc54d55141",
            "c454214fcb224f30b23920508405f479",
            "879a03e9ab4e4231809a53fc85e329fd",
            "6eccd9c499bc4051a8ef8fb3b994516f",
            "36cea72c31fb4f21a45803dfd02fe72f",
            "f0a2ca80c055490f9e236df0a2b310a9",
            "9db839401e294707b1e9d40425faac1f",
            "b9f2c0ce70364560b25e89c934d5df3d",
            "56342c30de844e5fa9dd97e419e32097",
            "7dedc6905ee247b7b3404741fad5b1ba"
          ]
        },
        "outputId": "ecea372c-726b-489b-af1b-509d3d0fc198"
      },
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e203260fc47e49eca3733a57f4e6fd1b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "44fcedaba19640798539feed184d367a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ecc4f94e49b545ea8bc0962019cfb8fa",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "64c6d0307cde4d4890345ce1ac1928c1",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4fb22149260b400fb05b5c25052c3436",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n",
            " 46%|████▌     | 44.5M/97.8M [00:01<00:02, 24.6MB/s]/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "100%|██████████| 97.8M/97.8M [00:04<00:00, 21.7MB/s]\n",
            "  0%|          | 0/9 [00:00<?, ?it/s]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Batch Labels: ['Calendars', '2016', 'No', 'Dog Page-A-Day Gallery Calendar 2016', 'Sandra Boynton', '2016', 'Calendars', 'Yes', 'No', 'Yes', 'No', 'Mary Engelbreit 2016 Deluxe Wall Calendar: Never Give Up', '2016', 'Calendars', 'Calendars', 'Yes', 'Susan Branch', 'Audubon Nature Wall Calendar 2016', '2016', 'No', 'No', '2016', \"The Old Farmer's Almanac 2016 Gardening Calendar\", 'Audubon Birds Page-A-Day Gallery Calendar 2016', '2016', 'Yes', 'Sierra Club Engagement Calendar 2016', 'Dale Chihuly', 'Mary Engelbreit', '2016', 'No', 'Yes']\n",
            "Mapped Labels: tensor([63, 38,  2, 37, 77, 38, 63, 50,  2, 50,  2, 11, 38, 63, 63, 50, 74, 10,\n",
            "        38,  2,  2, 38, 73, 49, 38, 50, 24, 23, 34, 38,  2, 50])\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            " 11%|█         | 1/9 [03:13<25:45, 193.24s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/5], Batch Loss: 4.4056\n",
            "Batch Labels: ['365 New Words-A-Year Page-A-Day Calendar 2016', 'Chihuly 2016 Wall Calendar', 'Calendars', 'Calendars', 'No', '2016', '2016', 'Amc', 'No', 'No', '2015', 'Cat Page-A-Day Gallery Calendar 2016', '2016', 'Calendars', 'Starz', 'Ansel Adams 2016 Wall Calendar', 'Once Upon a Time Wall Calendar (2016)', 'No', '2016', 'Calendars', 'No', 'No', 'Calendars', 'Calendars', 'Day Dream', 'Moleskine 2016 Weekly Notebook, 12M, Extra Large, Black, Soft Cover (7.5 x 10)', '2016', 'No', 'Thaneeya McArdle', '2016', '2016', 'Peter Pauper Press']\n",
            "Mapped Labels: tensor([31, 18, 63, 63,  2, 38, 38,  6,  2,  2,  9, 42, 38, 63, 43,  7, 71,  2,\n",
            "        38, 63,  2,  2, 63, 63, 36, 33, 38,  2, 58, 38, 38, 66])\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            " 22%|██▏       | 2/9 [06:16<21:50, 187.26s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/5], Batch Loss: 4.3123\n",
            "Batch Labels: ['Marty Jerome', 'No', 'Calendars', '2016 Almond Blossoms Weekly Planner (16-Month Engagement Calendar, Diary)', 'Calendars', 'Calendars', 'Calendars', '2016', 'Walking Dead 2016 Wall Calendar', '2016', 'Yes', 'Calendars', 'Calendars', '2016', 'Calendars', 'Mary Engelbreit 2016 Day-to-Day Calendar: Enjoy the Joy', 'Yes', '2016 Someecards Daily Desktop Calendar', 'Calendars', 'Moleskine 2016 Monthly Notebook, 12M, Extra Large, Black, Soft Cover (7.5 x 10)', 'Calendars', 'No', 'Doug the Pug', 'Moleskine', 'Calendars', '2016', 'No', 'Workman Publishing', 'Claire Belton', 'Amy Knapp', 'No', 'Calendars']\n",
            "Mapped Labels: tensor([87,  2, 63,  5, 63, 63, 63, 38, 67, 38, 50, 63, 63, 38, 63, 48, 50, 79,\n",
            "        63, 35, 63,  2, 85, 29, 63, 38,  2,  3, 61,  0,  2, 63])\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            " 33%|███▎      | 3/9 [08:56<17:28, 174.71s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/5], Batch Loss: 4.1055\n",
            "Batch Labels: ['Yes', 'Moleskine 2016 Weekly Notebook, 12M, Large, Black, Soft Cover (5 x 8.25)', 'No', 'Day Dream', 'No', 'Sierra Club', 'Yes', 'Calendars', 'Calendars', 'No', \"The Complete Runner's Day-by-Day Log 2016 Calendar\", '2016', \"Mom's Family Wall Calendar 2016\", 'A Song of Ice and Fire 2016 Calendar', 'No', 'Jane Meredith', 'Calendars', '2016', 'Merriam-Webster', 'No', '2016', 'No', 'Yes', 'Calendars', 'Thomas Kinkade', 'No', 'No', 'Calendars', 'No', 'Calendars', 'No', '2016']\n",
            "Mapped Labels: tensor([50, 56,  2, 36,  2, 52, 50, 63, 63,  2, 57, 38, 26, 81,  2, 78, 63, 38,\n",
            "        75,  2, 38,  2, 50, 63, 51,  2,  2, 63,  2, 63,  2, 38])\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            " 44%|████▍     | 4/9 [11:30<13:52, 166.56s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/5], Batch Loss: 4.0121\n",
            "Batch Labels: ['2016', 'MAXINE  Year-In-A-Box Calendar (2016)', 'Calendars', 'Calendars', 'Calendars', 'Moleskine', 'National Audubon Society', 'Posh: Coloring 2015-2016 Large Monthly/Weekly Planning Calendar', 'Yes', '2016', '2016', 'Yes', 'Old FarmerEEs Almanac', 'Calendars', 'Year-In-A-Box', '2016', '2016', 'No', 'Calendars', 'National Audubon Society', '2016', 'Calendars', \"Llewellyn's 2016 Witches' Calendar\", 'Nintendo', \"Llewellyn's 2016 Astrological Calendar: 83rd Edition of the World's Best Known, Most Trusted Astrology Calendar\", 'Moleskine 2015-2016 Weekly Notebook, 18M, Large, Black, Soft Cover (5 x 8.25)', 'No', 'Moleskine', 'Yes', 'Moleskine', 'Today Is Going to Be a Great Day! Color Page-A-Day Calendar 2016', 'Workman Publishing']\n",
            "Mapped Labels: tensor([38,  8, 63, 63, 63, 29, 59, 70, 50, 38, 38, 50, 16, 63, 47, 38, 38,  2,\n",
            "        63, 59, 38, 63, 21, 19, 84, 28,  2, 29, 50, 29, 27,  3])\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            " 56%|█████▌    | 5/9 [13:57<10:38, 159.54s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/5], Batch Loss: 3.9620\n",
            "Batch Labels: ['George R. R. Martin', '365 Cats Color Page-A-Day Calendar 2016', '2015', 'Llewellyn', '2016', 'The Legend of Zelda 2016 Wall Calendar', 'Someecards', '2016', 'No', 'Yes', 'Moleskine', 'Barbara Ardinger', 'Calendars', 'Calendars', 'Disney Descendants Wall Calendar (2016)', 'Workman Publishing', '2016', 'Calendars', 'Grumpy Cat', 'Calendars', 'Outlander 2016 Wall Calendar', 'French Country Diary 2016 Calendar', \"Mary Engelbreit 2016 Weekly Planner Calendar: Smile! It's Good For  You\", 'Calendars', 'Andrews McMeel Publishing LLC', '2016', 'No', '2016', '2016', 'No', 'Yes', 'Calendars']\n",
            "Mapped Labels: tensor([69, 39,  9, 41, 38, 45, 65, 38,  2, 50, 29, 20, 63, 63, 83,  3, 38, 63,\n",
            "        62, 63, 72, 46, 76, 63, 68, 38,  2, 38, 38,  2, 50, 63])\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            " 67%|██████▋   | 6/9 [16:26<07:48, 156.09s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/5], Batch Loss: 4.0743\n",
            "Batch Labels: ['2016', 'Calendars', '2016', 'No', 'Calendars', 'Pusheen the Cat 2016 Wall Calendar', 'Calendars', '2016', '2016', 'Linda Dannenberg', 'No', 'National Audubon Society', 'No', 'Thomas Kinkade: The Disney Dreams Collection 2016 Wall Calendar', 'No', '365 Dogs Color Page-A-Day Calendar 2016', '2016', 'Calendars', 'Color Your Year Wall Calendar 2016: Mindful Coloring Through the Seasons', 'Calendars', 'Sierra Club', 'No', 'No', 'Mary Engelbreit', 'No', '2016', 'Mary Engelbreit 2016 Monthly Pocket Planner: Just Being ME!', 'No', 'Doug the Pug 2016 Wall Calendar', 'Calendars', 'Mary Engelbreit', 'No']\n",
            "Mapped Labels: tensor([38, 63, 38,  2, 63, 32, 63, 38, 38, 12,  2, 59,  2, 30,  2, 53, 38, 63,\n",
            "        86, 63, 52,  2,  2, 34,  2, 38, 14,  2, 15, 63, 34,  2])\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            " 78%|███████▊  | 7/9 [18:47<05:02, 151.23s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/5], Batch Loss: 3.7068\n",
            "Batch Labels: ['2016', '2016', 'Audubon Engagement Calendar 2016', 'Grumpy Cat 2016 Wall Calendar', 'Scott Adams', 'Calendars', '2016 Susan Branch Wall Calendar', 'No', 'Anne Taintor', 'Yes', 'No', '2016 Amy Knapp Big Grid Wall Calendar: The essential organization and communication tool for the entire family', 'Posh: Coloring 2016 Day-to-Day Calendar: For Fun & Relaxation', 'Calendars', '2016', 'Calendars', 'Sierra Club Wilderness Calendar 2016', 'Workman Publishing', '2016', '2016', 'No', 'Workman Publishing', '2016', 'Dilbert 2016 Day-to-Day Calendar', '2016 National Park Foundation Wall Calendar', 'Yes', 'No', 'National Parks Foundation', 'No', \"Llewellyn's 2016 Witches' Datebook\", 'Yes', 'Calendars']\n",
            "Mapped Labels: tensor([38, 38,  4,  1, 80, 63, 64,  2, 22, 50,  2, 54, 55, 63, 38, 63, 40,  3,\n",
            "        38, 38,  2,  3, 38, 44, 25, 50,  2, 82,  2, 13, 50, 63])\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            " 89%|████████▉ | 8/9 [21:19<02:31, 151.45s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/5], Batch Loss: 3.9441\n",
            "Batch Labels: ['Calendars', 'Yes', '2016', '2016', '2016', 'Moleskine 2016 Weekly Notebook, 12M, Pocket, Black, Soft Cover (3.5 x 5.5)', '2016', 'Anne Taintor 2016 Wall Calendar', 'Workman Publishing', 'Mary Engelbreit', 'Yes']\n",
            "Mapped Labels: tensor([63, 50, 38, 38, 38, 60, 38, 17,  3, 34, 50])\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "100%|██████████| 9/9 [22:07<00:00, 147.51s/it]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/5], Batch Loss: 3.3592\n",
            "Epoch [1/5], Average Loss: 3.9869, Accuracy: 7.87%\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/9 [00:00<?, ?it/s]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Batch Labels: ['2016', \"The Old Farmer's Almanac 2016 Gardening Calendar\", 'Yes', '2016', \"The Complete Runner's Day-by-Day Log 2016 Calendar\", 'Calendars', 'Disney Descendants Wall Calendar (2016)', 'Yes', 'Sierra Club', 'Calendars', 'Anne Taintor 2016 Wall Calendar', '2016', 'Yes', '2016', 'Calendars', 'No', '2016', 'No', 'No', 'No', '2016', 'No', '2016', '2016', '2016', 'Calendars', 'Calendars', 'No', 'Sierra Club', '2016', 'No', 'Starz']\n",
            "Mapped Labels: tensor([38, 73, 50, 38, 57, 63, 83, 50, 52, 63, 17, 38, 50, 38, 63,  2, 38,  2,\n",
            "         2,  2, 38,  2, 38, 38, 38, 63, 63,  2, 52, 38,  2, 43])\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            " 11%|█         | 1/9 [02:21<18:48, 141.02s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [2/5], Batch Loss: 2.5597\n",
            "Batch Labels: ['Sandra Boynton', 'No', 'National Audubon Society', 'No', \"Llewellyn's 2016 Witches' Calendar\", 'Calendars', 'Calendars', '2016', 'Sierra Club Wilderness Calendar 2016', 'Yes', 'Workman Publishing', 'No', 'Calendars', '2016', 'Calendars', 'No', '2016', 'Audubon Engagement Calendar 2016', 'Old FarmerEEs Almanac', '2016 Amy Knapp Big Grid Wall Calendar: The essential organization and communication tool for the entire family', 'Mary Engelbreit', 'Jane Meredith', 'Audubon Birds Page-A-Day Gallery Calendar 2016', 'Posh: Coloring 2015-2016 Large Monthly/Weekly Planning Calendar', 'Moleskine', 'Andrews McMeel Publishing LLC', 'Calendars', '2016', 'Day Dream', 'Mary Engelbreit 2016 Day-to-Day Calendar: Enjoy the Joy', 'No', 'French Country Diary 2016 Calendar']\n",
            "Mapped Labels: tensor([77,  2, 59,  2, 21, 63, 63, 38, 40, 50,  3,  2, 63, 38, 63,  2, 38,  4,\n",
            "        16, 54, 34, 78, 49, 70, 29, 68, 63, 38, 36, 48,  2, 46])\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            " 22%|██▏       | 2/9 [04:44<16:38, 142.67s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [2/5], Batch Loss: 3.0788\n",
            "Batch Labels: [\"Llewellyn's 2016 Witches' Datebook\", 'Moleskine 2016 Weekly Notebook, 12M, Pocket, Black, Soft Cover (3.5 x 5.5)', 'Someecards', 'No', 'Calendars', 'Yes', '2016', '2016', 'Workman Publishing', 'Calendars', '2016', 'No', 'Calendars', 'Year-In-A-Box', 'George R. R. Martin', 'No', '2016', 'The Legend of Zelda 2016 Wall Calendar', 'No', 'Calendars', 'Calendars', 'Doug the Pug 2016 Wall Calendar', '2016', 'Posh: Coloring 2016 Day-to-Day Calendar: For Fun & Relaxation', '365 New Words-A-Year Page-A-Day Calendar 2016', 'Calendars', 'National Audubon Society', 'Yes', 'Marty Jerome', '2016', 'Calendars', 'No']\n",
            "Mapped Labels: tensor([13, 60, 65,  2, 63, 50, 38, 38,  3, 63, 38,  2, 63, 47, 69,  2, 38, 45,\n",
            "         2, 63, 63, 15, 38, 55, 31, 63, 59, 50, 87, 38, 63,  2])\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            " 33%|███▎      | 3/9 [07:09<14:20, 143.40s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [2/5], Batch Loss: 2.6764\n",
            "Batch Labels: ['Calendars', 'Calendars', 'Thaneeya McArdle', 'Grumpy Cat 2016 Wall Calendar', 'Pusheen the Cat 2016 Wall Calendar', '2016', '2016', 'Moleskine 2015-2016 Weekly Notebook, 18M, Large, Black, Soft Cover (5 x 8.25)', 'No', 'No', 'No', '2016', 'Calendars', 'Thomas Kinkade: The Disney Dreams Collection 2016 Wall Calendar', 'Peter Pauper Press', 'National Audubon Society', 'Workman Publishing', 'Calendars', 'Calendars', 'No', 'Amc', 'Yes', 'No', 'Calendars', '2016', '2016', 'Once Upon a Time Wall Calendar (2016)', '2016', 'Ansel Adams 2016 Wall Calendar', 'Today Is Going to Be a Great Day! Color Page-A-Day Calendar 2016', 'Cat Page-A-Day Gallery Calendar 2016', 'Linda Dannenberg']\n",
            "Mapped Labels: tensor([63, 63, 58,  1, 32, 38, 38, 28,  2,  2,  2, 38, 63, 30, 66, 59,  3, 63,\n",
            "        63,  2,  6, 50,  2, 63, 38, 38, 71, 38,  7, 27, 42, 12])\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            " 44%|████▍     | 4/9 [09:31<11:54, 142.92s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [2/5], Batch Loss: 2.7004\n",
            "Batch Labels: ['Llewellyn', 'Moleskine', 'Calendars', 'Yes', '2016', 'Yes', 'Calendars', 'No', 'Calendars', 'Calendars', '2016', 'Mary Engelbreit 2016 Monthly Pocket Planner: Just Being ME!', 'No', '365 Dogs Color Page-A-Day Calendar 2016', 'Moleskine', 'A Song of Ice and Fire 2016 Calendar', 'Calendars', 'Walking Dead 2016 Wall Calendar', '2016', '2016', 'No', 'Yes', '2015', 'Workman Publishing', 'Mary Engelbreit', 'Calendars', '365 Cats Color Page-A-Day Calendar 2016', 'Calendars', 'No', 'Claire Belton', '2016', 'No']\n",
            "Mapped Labels: tensor([41, 29, 63, 50, 38, 50, 63,  2, 63, 63, 38, 14,  2, 53, 29, 81, 63, 67,\n",
            "        38, 38,  2, 50,  9,  3, 34, 63, 39, 63,  2, 61, 38,  2])\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            " 56%|█████▌    | 5/9 [12:00<09:40, 145.14s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [2/5], Batch Loss: 2.4786\n",
            "Batch Labels: ['Scott Adams', 'Mary Engelbreit', '2016', 'Yes', 'No', '2016 Susan Branch Wall Calendar', '2016', 'No', 'No', 'No', 'Yes', 'No', 'Doug the Pug', '2016', '2016', 'Day Dream', 'No', 'Calendars', 'Nintendo', 'Mary Engelbreit', 'Yes', 'No', 'Susan Branch', '2016', '2016', 'Workman Publishing', 'Amy Knapp', '2016', 'Chihuly 2016 Wall Calendar', 'Calendars', 'Yes', '2016']\n",
            "Mapped Labels: tensor([80, 34, 38, 50,  2, 64, 38,  2,  2,  2, 50,  2, 85, 38, 38, 36,  2, 63,\n",
            "        19, 34, 50,  2, 74, 38, 38,  3,  0, 38, 18, 63, 50, 38])\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            " 67%|██████▋   | 6/9 [14:26<07:16, 145.40s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [2/5], Batch Loss: 2.2877\n",
            "Batch Labels: ['National Parks Foundation', 'No', 'Calendars', 'Calendars', 'Calendars', \"Llewellyn's 2016 Astrological Calendar: 83rd Edition of the World's Best Known, Most Trusted Astrology Calendar\", 'Dog Page-A-Day Gallery Calendar 2016', 'No', 'No', 'Calendars', 'MAXINE  Year-In-A-Box Calendar (2016)', '2016', 'Yes', '2016 Almond Blossoms Weekly Planner (16-Month Engagement Calendar, Diary)', '2016 National Park Foundation Wall Calendar', 'Calendars', '2016', 'Calendars', 'Outlander 2016 Wall Calendar', '2015', 'No', 'Moleskine 2016 Weekly Notebook, 12M, Large, Black, Soft Cover (5 x 8.25)', 'Moleskine', 'Mary Engelbreit 2016 Deluxe Wall Calendar: Never Give Up', 'Calendars', '2016', 'Dale Chihuly', 'No', '2016', 'Calendars', 'No', 'Merriam-Webster']\n",
            "Mapped Labels: tensor([82,  2, 63, 63, 63, 84, 37,  2,  2, 63,  8, 38, 50,  5, 25, 63, 38, 63,\n",
            "        72,  9,  2, 56, 29, 11, 63, 38, 23,  2, 38, 63,  2, 75])\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            " 78%|███████▊  | 7/9 [16:46<04:47, 143.73s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [2/5], Batch Loss: 2.3858\n",
            "Batch Labels: ['Calendars', '2016', 'Calendars', 'Audubon Nature Wall Calendar 2016', 'Workman Publishing', 'No', 'Calendars', 'Calendars', '2016', 'No', 'Moleskine', 'Barbara Ardinger', 'Calendars', '2016 Someecards Daily Desktop Calendar', 'Yes', 'Anne Taintor', 'No', 'Yes', '2016', \"Mom's Family Wall Calendar 2016\", '2016', 'Yes', 'Calendars', 'No', \"Mary Engelbreit 2016 Weekly Planner Calendar: Smile! It's Good For  You\", 'Calendars', '2016', 'Grumpy Cat', 'Sierra Club Engagement Calendar 2016', 'Yes', 'Calendars', 'Thomas Kinkade']\n",
            "Mapped Labels: tensor([63, 38, 63, 10,  3,  2, 63, 63, 38,  2, 29, 20, 63, 79, 50, 22,  2, 50,\n",
            "        38, 26, 38, 50, 63,  2, 76, 63, 38, 62, 24, 50, 63, 51])\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            " 89%|████████▉ | 8/9 [19:03<02:21, 141.50s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [2/5], Batch Loss: 2.1614\n",
            "Batch Labels: ['2016', 'Dilbert 2016 Day-to-Day Calendar', 'Color Your Year Wall Calendar 2016: Mindful Coloring Through the Seasons', 'No', 'Calendars', '2016', 'Moleskine 2016 Weekly Notebook, 12M, Extra Large, Black, Soft Cover (7.5 x 10)', 'Calendars', 'No', 'Yes', 'Moleskine 2016 Monthly Notebook, 12M, Extra Large, Black, Soft Cover (7.5 x 10)']\n",
            "Mapped Labels: tensor([38, 44, 86,  2, 63, 38, 33, 63,  2, 50, 35])\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "100%|██████████| 9/9 [19:53<00:00, 132.64s/it]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [2/5], Batch Loss: 2.2546\n",
            "Epoch [2/5], Average Loss: 2.5093, Accuracy: 48.31%\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/9 [00:00<?, ?it/s]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Batch Labels: ['No', 'No', 'Calendars', '2016', 'No', 'Susan Branch', 'Calendars', 'Calendars', 'Old FarmerEEs Almanac', 'Yes', 'Year-In-A-Box', 'National Audubon Society', 'Chihuly 2016 Wall Calendar', 'French Country Diary 2016 Calendar', 'Yes', 'Calendars', '2016', 'Yes', '2016', '2016', 'Day Dream', 'Dale Chihuly', 'No', 'No', 'Calendars', 'Sierra Club', 'No', 'Mary Engelbreit', 'Grumpy Cat', \"The Complete Runner's Day-by-Day Log 2016 Calendar\", '2016', 'No']\n",
            "Mapped Labels: tensor([ 2,  2, 63, 38,  2, 74, 63, 63, 16, 50, 47, 59, 18, 46, 50, 63, 38, 50,\n",
            "        38, 38, 36, 23,  2,  2, 63, 52,  2, 34, 62, 57, 38,  2])\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            " 11%|█         | 1/9 [02:25<19:26, 145.79s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [3/5], Batch Loss: 1.8308\n",
            "Batch Labels: ['Dilbert 2016 Day-to-Day Calendar', 'No', '2016', 'Mary Engelbreit 2016 Deluxe Wall Calendar: Never Give Up', \"Llewellyn's 2016 Astrological Calendar: 83rd Edition of the World's Best Known, Most Trusted Astrology Calendar\", '2016', '2016', 'National Audubon Society', 'Moleskine', 'No', 'Someecards', 'Mary Engelbreit', 'No', 'Barbara Ardinger', 'Calendars', 'Yes', '2016', 'Calendars', 'Moleskine 2016 Monthly Notebook, 12M, Extra Large, Black, Soft Cover (7.5 x 10)', '2016', 'No', 'No', '2016', 'Day Dream', 'Sierra Club', '2016', 'Starz', 'Outlander 2016 Wall Calendar', '2016', '2016', 'Moleskine 2016 Weekly Notebook, 12M, Extra Large, Black, Soft Cover (7.5 x 10)', 'Calendars']\n",
            "Mapped Labels: tensor([44,  2, 38, 11, 84, 38, 38, 59, 29,  2, 65, 34,  2, 20, 63, 50, 38, 63,\n",
            "        35, 38,  2,  2, 38, 36, 52, 38, 43, 72, 38, 38, 33, 63])\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            " 22%|██▏       | 2/9 [04:49<16:52, 144.66s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [3/5], Batch Loss: 1.8077\n",
            "Batch Labels: ['No', 'No', 'No', 'Calendars', 'Calendars', '2016', 'No', 'The Legend of Zelda 2016 Wall Calendar', 'Workman Publishing', 'No', '2016', 'Calendars', '2016', 'Audubon Nature Wall Calendar 2016', 'Sandra Boynton', 'Grumpy Cat 2016 Wall Calendar', 'Dog Page-A-Day Gallery Calendar 2016', '2016', 'No', 'No', '2016', 'Calendars', 'Mary Engelbreit', 'Peter Pauper Press', '365 Cats Color Page-A-Day Calendar 2016', 'No', 'No', \"The Old Farmer's Almanac 2016 Gardening Calendar\", 'No', 'No', '365 Dogs Color Page-A-Day Calendar 2016', 'Yes']\n",
            "Mapped Labels: tensor([ 2,  2,  2, 63, 63, 38,  2, 45,  3,  2, 38, 63, 38, 10, 77,  1, 37, 38,\n",
            "         2,  2, 38, 63, 34, 66, 39,  2,  2, 73,  2,  2, 53, 50])\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            " 33%|███▎      | 3/9 [07:08<14:12, 142.01s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [3/5], Batch Loss: 1.6315\n",
            "Batch Labels: ['Walking Dead 2016 Wall Calendar', 'Calendars', 'Moleskine', 'No', '2016', 'Today Is Going to Be a Great Day! Color Page-A-Day Calendar 2016', '2016 National Park Foundation Wall Calendar', 'Yes', 'Claire Belton', '2016 Someecards Daily Desktop Calendar', 'Calendars', 'Calendars', 'No', 'Calendars', 'Yes', 'Anne Taintor 2016 Wall Calendar', 'Pusheen the Cat 2016 Wall Calendar', 'Calendars', 'Calendars', 'Calendars', '2016', 'Mary Engelbreit', 'Yes', 'No', '2016', 'Posh: Coloring 2016 Day-to-Day Calendar: For Fun & Relaxation', '2016', '2016', 'Calendars', 'Calendars', 'Audubon Birds Page-A-Day Gallery Calendar 2016', 'Thomas Kinkade: The Disney Dreams Collection 2016 Wall Calendar']\n",
            "Mapped Labels: tensor([67, 63, 29,  2, 38, 27, 25, 50, 61, 79, 63, 63,  2, 63, 50, 17, 32, 63,\n",
            "        63, 63, 38, 34, 50,  2, 38, 55, 38, 38, 63, 63, 49, 30])\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            " 44%|████▍     | 4/9 [09:32<11:54, 142.88s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [3/5], Batch Loss: 1.6069\n",
            "Batch Labels: ['2016', 'National Parks Foundation', 'Workman Publishing', '2016', '2016 Susan Branch Wall Calendar', 'Moleskine 2016 Weekly Notebook, 12M, Pocket, Black, Soft Cover (3.5 x 5.5)', 'Sierra Club Engagement Calendar 2016', 'Yes', 'Yes', 'Scott Adams', 'Calendars', 'George R. R. Martin', 'Calendars', 'Calendars', 'Calendars', 'Calendars', 'Amc', '2016', 'Workman Publishing', 'Calendars', 'No', 'National Audubon Society', '2016', 'Calendars', 'Yes', 'Color Your Year Wall Calendar 2016: Mindful Coloring Through the Seasons', 'No', 'Anne Taintor', 'Moleskine 2016 Weekly Notebook, 12M, Large, Black, Soft Cover (5 x 8.25)', 'Calendars', 'Yes', 'Calendars']\n",
            "Mapped Labels: tensor([38, 82,  3, 38, 64, 60, 24, 50, 50, 80, 63, 69, 63, 63, 63, 63,  6, 38,\n",
            "         3, 63,  2, 59, 38, 63, 50, 86,  2, 22, 56, 63, 50, 63])\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            " 56%|█████▌    | 5/9 [11:49<09:22, 140.55s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [3/5], Batch Loss: 1.9472\n",
            "Batch Labels: ['Calendars', 'No', 'Calendars', 'No', '2016', 'Calendars', 'Yes', 'Calendars', 'No', 'Calendars', 'Calendars', 'Yes', '365 New Words-A-Year Page-A-Day Calendar 2016', 'MAXINE  Year-In-A-Box Calendar (2016)', 'No', 'Yes', 'Jane Meredith', 'No', 'Calendars', '2016', 'Doug the Pug 2016 Wall Calendar', 'Amy Knapp', 'No', 'Sierra Club Wilderness Calendar 2016', 'No', 'Calendars', 'Thomas Kinkade', 'Yes', 'Yes', \"Mom's Family Wall Calendar 2016\", '2016', 'Calendars']\n",
            "Mapped Labels: tensor([63,  2, 63,  2, 38, 63, 50, 63,  2, 63, 63, 50, 31,  8,  2, 50, 78,  2,\n",
            "        63, 38, 15,  0,  2, 40,  2, 63, 51, 50, 50, 26, 38, 63])\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            " 67%|██████▋   | 6/9 [14:14<07:06, 142.15s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [3/5], Batch Loss: 1.5155\n",
            "Batch Labels: ['2016', '2016', '2016', 'Calendars', 'Mary Engelbreit 2016 Monthly Pocket Planner: Just Being ME!', 'No', 'Doug the Pug', 'Disney Descendants Wall Calendar (2016)', '2016', '2016', 'Linda Dannenberg', 'No', '2015', '2016 Almond Blossoms Weekly Planner (16-Month Engagement Calendar, Diary)', '2016', 'Once Upon a Time Wall Calendar (2016)', 'Llewellyn', 'Calendars', 'Calendars', '2016', '2016', '2016', 'No', '2016', 'A Song of Ice and Fire 2016 Calendar', 'Posh: Coloring 2015-2016 Large Monthly/Weekly Planning Calendar', '2016', 'Nintendo', 'Calendars', 'Cat Page-A-Day Gallery Calendar 2016', 'Moleskine', 'No']\n",
            "Mapped Labels: tensor([38, 38, 38, 63, 14,  2, 85, 83, 38, 38, 12,  2,  9,  5, 38, 71, 41, 63,\n",
            "        63, 38, 38, 38,  2, 38, 81, 70, 38, 19, 63, 42, 29,  2])\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            " 78%|███████▊  | 7/9 [16:35<04:43, 141.94s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [3/5], Batch Loss: 1.6542\n",
            "Batch Labels: ['2016', 'Calendars', 'Ansel Adams 2016 Wall Calendar', 'Merriam-Webster', \"Mary Engelbreit 2016 Weekly Planner Calendar: Smile! It's Good For  You\", '2016', '2016', '2016', '2016', 'Thaneeya McArdle', 'No', 'Workman Publishing', 'Calendars', '2016', '2016', '2016 Amy Knapp Big Grid Wall Calendar: The essential organization and communication tool for the entire family', 'Calendars', 'No', 'No', 'Andrews McMeel Publishing LLC', 'Calendars', 'Moleskine', 'Workman Publishing', 'Calendars', 'Calendars', 'Moleskine 2015-2016 Weekly Notebook, 18M, Large, Black, Soft Cover (5 x 8.25)', 'No', 'Marty Jerome', 'No', \"Llewellyn's 2016 Witches' Calendar\", 'Workman Publishing', \"Llewellyn's 2016 Witches' Datebook\"]\n",
            "Mapped Labels: tensor([38, 63,  7, 75, 76, 38, 38, 38, 38, 58,  2,  3, 63, 38, 38, 54, 63,  2,\n",
            "         2, 68, 63, 29,  3, 63, 63, 28,  2, 87,  2, 21,  3, 13])\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            " 89%|████████▉ | 8/9 [18:52<02:20, 140.33s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [3/5], Batch Loss: 1.6489\n",
            "Batch Labels: ['Yes', 'Yes', 'Calendars', 'Audubon Engagement Calendar 2016', 'Moleskine', '2016', 'No', 'Mary Engelbreit 2016 Day-to-Day Calendar: Enjoy the Joy', '2015', 'Yes', 'No']\n",
            "Mapped Labels: tensor([50, 50, 63,  4, 29, 38,  2, 48,  9, 50,  2])\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "100%|██████████| 9/9 [19:45<00:00, 131.74s/it]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [3/5], Batch Loss: 1.8572\n",
            "Epoch [3/5], Average Loss: 1.7222, Accuracy: 65.54%\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/9 [00:00<?, ?it/s]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Batch Labels: ['Workman Publishing', '2016', 'Posh: Coloring 2016 Day-to-Day Calendar: For Fun & Relaxation', 'Calendars', '2015', '2016', 'French Country Diary 2016 Calendar', 'Yes', 'Workman Publishing', 'Calendars', 'Yes', 'Calendars', '2016', 'Calendars', 'Yes', 'No', '2016', 'Calendars', \"Llewellyn's 2016 Witches' Calendar\", 'Moleskine 2016 Monthly Notebook, 12M, Extra Large, Black, Soft Cover (7.5 x 10)', 'Mary Engelbreit 2016 Day-to-Day Calendar: Enjoy the Joy', '2016 Amy Knapp Big Grid Wall Calendar: The essential organization and communication tool for the entire family', '2016', 'No', 'No', 'Yes', 'No', 'Doug the Pug', 'Calendars', '365 Cats Color Page-A-Day Calendar 2016', 'Once Upon a Time Wall Calendar (2016)', 'Moleskine 2016 Weekly Notebook, 12M, Large, Black, Soft Cover (5 x 8.25)']\n",
            "Mapped Labels: tensor([ 3, 38, 55, 63,  9, 38, 46, 50,  3, 63, 50, 63, 38, 63, 50,  2, 38, 63,\n",
            "        21, 35, 48, 54, 38,  2,  2, 50,  2, 85, 63, 39, 71, 56])\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            " 11%|█         | 1/9 [02:19<18:39, 139.91s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [4/5], Batch Loss: 1.4567\n",
            "Batch Labels: ['Scott Adams', 'Sierra Club Wilderness Calendar 2016', \"The Complete Runner's Day-by-Day Log 2016 Calendar\", 'Calendars', '2016', 'Yes', \"Llewellyn's 2016 Astrological Calendar: 83rd Edition of the World's Best Known, Most Trusted Astrology Calendar\", 'Thomas Kinkade', '2016', 'Calendars', 'Dale Chihuly', 'Calendars', 'Calendars', 'Workman Publishing', 'Someecards', 'Yes', '2016', 'Calendars', '2016', 'No', 'Calendars', 'Barbara Ardinger', 'Color Your Year Wall Calendar 2016: Mindful Coloring Through the Seasons', 'Claire Belton', 'Disney Descendants Wall Calendar (2016)', '2016', '365 New Words-A-Year Page-A-Day Calendar 2016', 'No', 'No', 'Moleskine', 'No', 'Peter Pauper Press']\n",
            "Mapped Labels: tensor([80, 40, 57, 63, 38, 50, 84, 51, 38, 63, 23, 63, 63,  3, 65, 50, 38, 63,\n",
            "        38,  2, 63, 20, 86, 61, 83, 38, 31,  2,  2, 29,  2, 66])\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            " 22%|██▏       | 2/9 [04:37<16:08, 138.42s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [4/5], Batch Loss: 1.4402\n",
            "Batch Labels: ['Audubon Birds Page-A-Day Gallery Calendar 2016', 'Moleskine', 'Moleskine 2016 Weekly Notebook, 12M, Extra Large, Black, Soft Cover (7.5 x 10)', '365 Dogs Color Page-A-Day Calendar 2016', \"Llewellyn's 2016 Witches' Datebook\", '2016', 'No', 'Walking Dead 2016 Wall Calendar', 'Yes', 'Yes', 'National Audubon Society', 'No', 'Calendars', 'Doug the Pug 2016 Wall Calendar', 'No', 'Calendars', 'No', 'Calendars', '2016', 'Mary Engelbreit', 'Outlander 2016 Wall Calendar', 'Calendars', 'Yes', '2016', 'Starz', '2016', 'Moleskine', '2016', 'Mary Engelbreit 2016 Deluxe Wall Calendar: Never Give Up', '2016', '2016', 'Calendars']\n",
            "Mapped Labels: tensor([49, 29, 33, 53, 13, 38,  2, 67, 50, 50, 59,  2, 63, 15,  2, 63,  2, 63,\n",
            "        38, 34, 72, 63, 50, 38, 43, 38, 29, 38, 11, 38, 38, 63])\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            " 33%|███▎      | 3/9 [06:56<13:53, 138.86s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [4/5], Batch Loss: 1.2328\n",
            "Batch Labels: ['Calendars', 'Workman Publishing', 'Calendars', 'No', 'Yes', '2016', 'No', '2016 National Park Foundation Wall Calendar', 'Calendars', '2016', 'Yes', 'Sierra Club', 'Yes', 'Calendars', '2016 Almond Blossoms Weekly Planner (16-Month Engagement Calendar, Diary)', 'Calendars', 'Calendars', 'MAXINE  Year-In-A-Box Calendar (2016)', 'Anne Taintor', 'Amc', 'Calendars', 'George R. R. Martin', 'Merriam-Webster', 'Calendars', '2016', '2016', 'Calendars', '2016', '2016', '2016', 'No', 'No']\n",
            "Mapped Labels: tensor([63,  3, 63,  2, 50, 38,  2, 25, 63, 38, 50, 52, 50, 63,  5, 63, 63,  8,\n",
            "        22,  6, 63, 69, 75, 63, 38, 38, 63, 38, 38, 38,  2,  2])\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            " 44%|████▍     | 4/9 [09:15<11:33, 138.69s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [4/5], Batch Loss: 1.0568\n",
            "Batch Labels: ['2016', \"Mary Engelbreit 2016 Weekly Planner Calendar: Smile! It's Good For  You\", 'Calendars', 'No', 'No', '2016', 'Linda Dannenberg', 'Calendars', 'Moleskine', '2016', 'Calendars', 'Calendars', 'A Song of Ice and Fire 2016 Calendar', 'No', 'Grumpy Cat', 'Calendars', '2016', 'Calendars', 'Calendars', 'Mary Engelbreit', 'Susan Branch', 'Calendars', 'Workman Publishing', 'No', 'No', 'Posh: Coloring 2015-2016 Large Monthly/Weekly Planning Calendar', 'Calendars', 'Calendars', '2016', 'Yes', 'No', 'National Audubon Society']\n",
            "Mapped Labels: tensor([38, 76, 63,  2,  2, 38, 12, 63, 29, 38, 63, 63, 81,  2, 62, 63, 38, 63,\n",
            "        63, 34, 74, 63,  3,  2,  2, 70, 63, 63, 38, 50,  2, 59])\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            " 56%|█████▌    | 5/9 [11:32<09:13, 138.30s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [4/5], Batch Loss: 0.9862\n",
            "Batch Labels: ['No', 'Sandra Boynton', 'No', 'Calendars', 'Calendars', 'No', 'No', 'No', '2016', 'No', 'Yes', 'Calendars', 'Calendars', 'Nintendo', 'Day Dream', 'Moleskine', 'No', 'Sierra Club Engagement Calendar 2016', 'No', '2016', '2016', 'Moleskine 2016 Weekly Notebook, 12M, Pocket, Black, Soft Cover (3.5 x 5.5)', 'Mary Engelbreit', 'No', 'Calendars', 'Yes', '2016', 'Chihuly 2016 Wall Calendar', '2016', 'No', 'Jane Meredith', 'Calendars']\n",
            "Mapped Labels: tensor([ 2, 77,  2, 63, 63,  2,  2,  2, 38,  2, 50, 63, 63, 19, 36, 29,  2, 24,\n",
            "         2, 38, 38, 60, 34,  2, 63, 50, 38, 18, 38,  2, 78, 63])\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            " 67%|██████▋   | 6/9 [13:53<06:57, 139.25s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [4/5], Batch Loss: 0.9262\n",
            "Batch Labels: ['No', '2016', 'Audubon Engagement Calendar 2016', 'Anne Taintor 2016 Wall Calendar', '2016', 'Audubon Nature Wall Calendar 2016', 'Calendars', '2016', 'No', 'Grumpy Cat 2016 Wall Calendar', '2016', 'No', 'No', 'Year-In-A-Box', 'Thaneeya McArdle', 'No', 'Calendars', 'Ansel Adams 2016 Wall Calendar', '2016', 'Amy Knapp', 'Yes', 'Mary Engelbreit 2016 Monthly Pocket Planner: Just Being ME!', 'Calendars', 'National Audubon Society', '2016 Someecards Daily Desktop Calendar', 'No', '2016', 'The Legend of Zelda 2016 Wall Calendar', 'Calendars', 'Old FarmerEEs Almanac', 'Yes', '2016']\n",
            "Mapped Labels: tensor([ 2, 38,  4, 17, 38, 10, 63, 38,  2,  1, 38,  2,  2, 47, 58,  2, 63,  7,\n",
            "        38,  0, 50, 14, 63, 59, 79,  2, 38, 45, 63, 16, 50, 38])\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            " 78%|███████▊  | 7/9 [16:12<04:37, 138.93s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [4/5], Batch Loss: 1.4470\n",
            "Batch Labels: ['Yes', '2016', 'Yes', 'No', '2016', 'National Parks Foundation', 'Llewellyn', 'Calendars', '2016 Susan Branch Wall Calendar', 'Moleskine 2015-2016 Weekly Notebook, 18M, Large, Black, Soft Cover (5 x 8.25)', 'No', 'Calendars', 'Calendars', 'No', '2016', '2016', '2016', 'Marty Jerome', '2016', 'Mary Engelbreit', 'Pusheen the Cat 2016 Wall Calendar', 'No', 'No', 'Calendars', 'Dog Page-A-Day Gallery Calendar 2016', '2016', 'Workman Publishing', 'Dilbert 2016 Day-to-Day Calendar', 'Cat Page-A-Day Gallery Calendar 2016', '2015', 'No', 'Yes']\n",
            "Mapped Labels: tensor([50, 38, 50,  2, 38, 82, 41, 63, 64, 28,  2, 63, 63,  2, 38, 38, 38, 87,\n",
            "        38, 34, 32,  2,  2, 63, 37, 38,  3, 44, 42,  9,  2, 50])\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            " 89%|████████▉ | 8/9 [18:33<02:19, 139.87s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [4/5], Batch Loss: 1.2055\n",
            "Batch Labels: ['No', '2016', 'Day Dream', 'No', \"Mom's Family Wall Calendar 2016\", 'Sierra Club', 'Andrews McMeel Publishing LLC', \"The Old Farmer's Almanac 2016 Gardening Calendar\", '2016', 'Thomas Kinkade: The Disney Dreams Collection 2016 Wall Calendar', 'Today Is Going to Be a Great Day! Color Page-A-Day Calendar 2016']\n",
            "Mapped Labels: tensor([ 2, 38, 36,  2, 26, 52, 68, 73, 38, 30, 27])\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "100%|██████████| 9/9 [19:24<00:00, 129.42s/it]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [4/5], Batch Loss: 1.9671\n",
            "Epoch [4/5], Average Loss: 1.3020, Accuracy: 73.41%\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/9 [00:00<?, ?it/s]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Batch Labels: ['Workman Publishing', 'Amy Knapp', '2016', 'No', 'National Audubon Society', 'Thaneeya McArdle', 'Calendars', 'Day Dream', 'Claire Belton', 'Mary Engelbreit 2016 Day-to-Day Calendar: Enjoy the Joy', 'No', '2016', 'Calendars', 'Calendars', 'Calendars', '2016 Someecards Daily Desktop Calendar', '2016', 'Calendars', '2016', 'Grumpy Cat 2016 Wall Calendar', 'No', 'Doug the Pug', 'Someecards', 'Yes', 'Starz', 'Sandra Boynton', 'Mary Engelbreit', 'No', '2016', \"Mary Engelbreit 2016 Weekly Planner Calendar: Smile! It's Good For  You\", '2016', 'Color Your Year Wall Calendar 2016: Mindful Coloring Through the Seasons']\n",
            "Mapped Labels: tensor([ 3,  0, 38,  2, 59, 58, 63, 36, 61, 48,  2, 38, 63, 63, 63, 79, 38, 63,\n",
            "        38,  1,  2, 85, 65, 50, 43, 77, 34,  2, 38, 76, 38, 86])\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            " 11%|█         | 1/9 [02:13<17:51, 133.95s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [5/5], Batch Loss: 1.2540\n",
            "Batch Labels: ['2016', 'Thomas Kinkade: The Disney Dreams Collection 2016 Wall Calendar', 'Posh: Coloring 2016 Day-to-Day Calendar: For Fun & Relaxation', 'Calendars', 'Andrews McMeel Publishing LLC', 'Thomas Kinkade', 'No', '2016', 'Calendars', '2016', 'Chihuly 2016 Wall Calendar', 'Calendars', 'No', 'Calendars', 'A Song of Ice and Fire 2016 Calendar', 'No', 'Yes', 'Moleskine', 'Calendars', 'Ansel Adams 2016 Wall Calendar', '2016', 'Mary Engelbreit 2016 Deluxe Wall Calendar: Never Give Up', 'National Audubon Society', 'Yes', 'Workman Publishing', 'Posh: Coloring 2015-2016 Large Monthly/Weekly Planning Calendar', 'Calendars', 'No', '2016', 'Yes', 'Calendars', 'Jane Meredith']\n",
            "Mapped Labels: tensor([38, 30, 55, 63, 68, 51,  2, 38, 63, 38, 18, 63,  2, 63, 81,  2, 50, 29,\n",
            "        63,  7, 38, 11, 59, 50,  3, 70, 63,  2, 38, 50, 63, 78])\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            " 22%|██▏       | 2/9 [04:36<16:14, 139.15s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [5/5], Batch Loss: 1.0410\n",
            "Batch Labels: ['2016', '2016 Amy Knapp Big Grid Wall Calendar: The essential organization and communication tool for the entire family', 'Calendars', 'Day Dream', '2016 Susan Branch Wall Calendar', '2016', 'Amc', 'Once Upon a Time Wall Calendar (2016)', 'Calendars', 'No', 'No', 'No', '2016', 'Calendars', '2016', 'Calendars', '2016', 'Calendars', '2016', '2016', '2015', 'No', 'Yes', 'Moleskine', 'Calendars', 'Sierra Club', 'Moleskine', 'No', 'Barbara Ardinger', '2016', 'No', 'Yes']\n",
            "Mapped Labels: tensor([38, 54, 63, 36, 64, 38,  6, 71, 63,  2,  2,  2, 38, 63, 38, 63, 38, 63,\n",
            "        38, 38,  9,  2, 50, 29, 63, 52, 29,  2, 20, 38,  2, 50])\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            " 33%|███▎      | 3/9 [07:01<14:09, 141.55s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [5/5], Batch Loss: 0.8098\n",
            "Batch Labels: ['Calendars', 'No', 'No', \"Llewellyn's 2016 Astrological Calendar: 83rd Edition of the World's Best Known, Most Trusted Astrology Calendar\", 'Audubon Engagement Calendar 2016', 'Moleskine', 'Yes', 'Moleskine 2016 Weekly Notebook, 12M, Pocket, Black, Soft Cover (3.5 x 5.5)', 'Anne Taintor', 'Susan Branch', 'Moleskine', 'No', '2016', 'Calendars', '2016 National Park Foundation Wall Calendar', 'Grumpy Cat', 'Cat Page-A-Day Gallery Calendar 2016', 'Scott Adams', 'Calendars', 'No', 'No', 'No', 'Yes', 'No', 'Old FarmerEEs Almanac', 'No', 'Calendars', 'No', 'Calendars', 'Yes', 'Dilbert 2016 Day-to-Day Calendar', '2016']\n",
            "Mapped Labels: tensor([63,  2,  2, 84,  4, 29, 50, 60, 22, 74, 29,  2, 38, 63, 25, 62, 42, 80,\n",
            "        63,  2,  2,  2, 50,  2, 16,  2, 63,  2, 63, 50, 44, 38])\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            " 44%|████▍     | 4/9 [09:20<11:44, 140.87s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [5/5], Batch Loss: 1.0789\n",
            "Batch Labels: ['2016', '2016', 'Calendars', 'National Audubon Society', 'Calendars', '2016', 'Calendars', '2016', 'Calendars', 'Workman Publishing', 'Yes', 'Merriam-Webster', 'Calendars', 'Audubon Birds Page-A-Day Gallery Calendar 2016', 'The Legend of Zelda 2016 Wall Calendar', 'Calendars', 'Calendars', '2016', 'Pusheen the Cat 2016 Wall Calendar', 'Mary Engelbreit', 'Yes', 'Calendars', 'Yes', 'Calendars', \"Llewellyn's 2016 Witches' Calendar\", 'Sierra Club Wilderness Calendar 2016', '2016', 'Today Is Going to Be a Great Day! Color Page-A-Day Calendar 2016', '2016', '2016 Almond Blossoms Weekly Planner (16-Month Engagement Calendar, Diary)', 'Linda Dannenberg', 'No']\n",
            "Mapped Labels: tensor([38, 38, 63, 59, 63, 38, 63, 38, 63,  3, 50, 75, 63, 49, 45, 63, 63, 38,\n",
            "        32, 34, 50, 63, 50, 63, 21, 40, 38, 27, 38,  5, 12,  2])\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            " 56%|█████▌    | 5/9 [11:43<09:26, 141.57s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [5/5], Batch Loss: 0.8838\n",
            "Batch Labels: ['365 Dogs Color Page-A-Day Calendar 2016', 'Calendars', 'No', 'No', 'Calendars', 'No', '2016', 'Sierra Club Engagement Calendar 2016', 'Calendars', 'No', 'Workman Publishing', '2016', 'No', 'No', 'Year-In-A-Box', 'No', 'Dog Page-A-Day Gallery Calendar 2016', 'Sierra Club', 'Dale Chihuly', 'National Parks Foundation', 'No', 'Mary Engelbreit', 'Mary Engelbreit 2016 Monthly Pocket Planner: Just Being ME!', 'Audubon Nature Wall Calendar 2016', 'No', 'No', 'Llewellyn', '2016', 'Calendars', 'Doug the Pug 2016 Wall Calendar', 'Yes', 'No']\n",
            "Mapped Labels: tensor([53, 63,  2,  2, 63,  2, 38, 24, 63,  2,  3, 38,  2,  2, 47,  2, 37, 52,\n",
            "        23, 82,  2, 34, 14, 10,  2,  2, 41, 38, 63, 15, 50,  2])\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            " 67%|██████▋   | 6/9 [14:00<07:00, 140.02s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [5/5], Batch Loss: 1.0195\n",
            "Batch Labels: [\"The Complete Runner's Day-by-Day Log 2016 Calendar\", 'Calendars', 'Moleskine 2016 Weekly Notebook, 12M, Large, Black, Soft Cover (5 x 8.25)', 'No', 'No', 'Yes', 'No', \"Llewellyn's 2016 Witches' Datebook\", '2016', 'Moleskine 2016 Monthly Notebook, 12M, Extra Large, Black, Soft Cover (7.5 x 10)', 'Calendars', '2016', \"The Old Farmer's Almanac 2016 Gardening Calendar\", 'No', 'French Country Diary 2016 Calendar', 'George R. R. Martin', '2016', 'Walking Dead 2016 Wall Calendar', 'Yes', 'Marty Jerome', '2016', 'Calendars', 'Calendars', 'Disney Descendants Wall Calendar (2016)', 'Yes', 'Calendars', '2016', 'No', 'Workman Publishing', 'Mary Engelbreit', 'Moleskine 2016 Weekly Notebook, 12M, Extra Large, Black, Soft Cover (7.5 x 10)', 'Nintendo']\n",
            "Mapped Labels: tensor([57, 63, 56,  2,  2, 50,  2, 13, 38, 35, 63, 38, 73,  2, 46, 69, 38, 67,\n",
            "        50, 87, 38, 63, 63, 83, 50, 63, 38,  2,  3, 34, 33, 19])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            " 78%|███████▊  | 7/9 [16:24<04:42, 141.32s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [5/5], Batch Loss: 1.2199\n",
            "Batch Labels: ['2016', '2016', 'Yes', 'Outlander 2016 Wall Calendar', 'Calendars', 'Yes', 'Workman Publishing', 'No', 'Calendars', \"Mom's Family Wall Calendar 2016\", '2015', 'No', 'Moleskine 2015-2016 Weekly Notebook, 18M, Large, Black, Soft Cover (5 x 8.25)', 'Yes', '2016', '2016', '2016', 'No', '2016', 'Calendars', '2016', 'Calendars', '2016', 'Calendars', '2016', 'No', 'Calendars', 'Yes', 'MAXINE  Year-In-A-Box Calendar (2016)', '365 New Words-A-Year Page-A-Day Calendar 2016', '2016', 'Anne Taintor 2016 Wall Calendar']\n",
            "Mapped Labels: tensor([38, 38, 50, 72, 63, 50,  3,  2, 63, 26,  9,  2, 28, 50, 38, 38, 38,  2,\n",
            "        38, 63, 38, 63, 38, 63, 38,  2, 63, 50,  8, 31, 38, 17])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            " 89%|████████▉ | 8/9 [18:36<02:18, 138.28s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [5/5], Batch Loss: 0.7005\n",
            "Batch Labels: ['Calendars', '365 Cats Color Page-A-Day Calendar 2016', 'No', 'Peter Pauper Press', '2016', '2016', 'Calendars', 'Calendars', '2016', '2016', 'No']\n",
            "Mapped Labels: tensor([63, 39,  2, 66, 38, 38, 63, 63, 38, 38,  2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "100%|██████████| 9/9 [19:26<00:00, 129.60s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [5/5], Batch Loss: 0.6700\n",
            "Epoch [5/5], Average Loss: 0.9642, Accuracy: 81.65%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from io import BytesIO\n",
        "from PIL import UnidentifiedImageError\n",
        "\n",
        "def test_single_input(model, tokenizer, image_transform, text, image_url):\n",
        "    model.eval()\n",
        "\n",
        "    # Process the text input\n",
        "    text_inputs = tokenizer(text, padding=True, truncation=True, return_tensors='pt').to(device)\n",
        "\n",
        "    try:\n",
        "        # Download and process the image input\n",
        "        response = requests.get(image_url)\n",
        "        response.raise_for_status()  # Raise HTTPError for bad responses\n",
        "        image = Image.open(BytesIO(response.content))\n",
        "        if image_transform:\n",
        "            image = image_transform(image).unsqueeze(0).to(device)\n",
        "    except (requests.exceptions.RequestException, UnidentifiedImageError) as e:\n",
        "        print(f\"Error loading image: {e}\")\n",
        "        return None\n",
        "\n",
        "    with torch.no_grad():\n",
        "        text_outputs = model.bert(**text_inputs)\n",
        "        text_embedding = text_outputs.pooler_output\n",
        "        image_embedding = model.resnet(image)\n",
        "        combined = torch.cat((text_embedding, image_embedding), dim=1)\n",
        "        output = model.fc(combined)\n",
        "\n",
        "    _, predicted_label_idx = torch.max(output, 1)\n",
        "    predicted_label = list(label_to_index.keys())[list(label_to_index.values()).index(predicted_label_idx.item())]\n",
        "\n",
        "    return predicted_label\n",
        "\n",
        "# Example usage of the test function with a valid image URL\n",
        "text = \"What is the title of the book?\"\n",
        "image_url = \"http://ecx.images-amazon.com/images/I/61Y5cOdHJbL.jpg\"  # Replace with a valid image URL\n",
        "predicted_label = test_single_input(model, model.bert_tokenizer, image_transform, text, image_url)\n",
        "print(f\"Predicted Label: {predicted_label}\")\n"
      ],
      "metadata": {
        "id": "VhraT1r-WfNb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c20eb4c4-469c-455d-a763-a8f5d58d477a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted Label: Mom's Family Wall Calendar 2016\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import requests\n",
        "from io import BytesIO\n",
        "from PIL import Image, UnidentifiedImageError\n",
        "import random\n",
        "\n",
        "def test_single_input(model, tokenizer, image_transform, text, image_path, expected_label):\n",
        "    model.eval()\n",
        "\n",
        "    # Process the text input\n",
        "    text_inputs = tokenizer(text, padding=True, truncation=True, return_tensors='pt').to(device)\n",
        "\n",
        "    try:\n",
        "        # Load and process the image input from local file\n",
        "        image = Image.open(image_path)\n",
        "        if image_transform:\n",
        "            image = image_transform(image).unsqueeze(0).to(device)\n",
        "    except UnidentifiedImageError as e:\n",
        "        print(f\"Error loading image: {e}\")\n",
        "        return None\n",
        "\n",
        "    with torch.no_grad():\n",
        "        text_outputs = model.bert(**text_inputs)\n",
        "        text_embedding = text_outputs.pooler_output\n",
        "        image_embedding = model.resnet(image)\n",
        "        combined = torch.cat((text_embedding, image_embedding), dim=1)\n",
        "        output = model.fc(combined)\n",
        "\n",
        "    _, predicted_label_idx = torch.max(output, 1)\n",
        "    predicted_label = list(label_to_index.keys())[list(label_to_index.values()).index(predicted_label_idx.item())]\n",
        "\n",
        "    print(f\"Predicted Label: {predicted_label}\")\n",
        "    print(f\"Expected Label: {expected_label}\")\n",
        "\n",
        "    return predicted_label\n",
        "\n",
        "# Load processed data\n",
        "processed_data = pd.read_csv('processed_murag_data.csv')\n",
        "\n",
        "# Randomly select 3 entries from the dataset\n",
        "random_indices = random.sample(range(len(processed_data)), 3)\n",
        "for idx in random_indices:\n",
        "    context = eval(processed_data.iloc[idx]['context'])  # Evaluate the context dictionary\n",
        "    image_path = context['image_path']                  # Extract the image path\n",
        "    text = processed_data.iloc[idx]['question']         # Extract the question\n",
        "    expected_label = processed_data.iloc[idx]['answer'] # Extract the expected answer\n",
        "\n",
        "    print(f\"Testing entry {idx}:\")\n",
        "    # Check if the file exists\n",
        "    if not os.path.isfile(image_path):\n",
        "        print(f\"Image file does not exist: {image_path}\")\n",
        "    else:\n",
        "        # Run the test\n",
        "        predicted_label = test_single_input(model, model.bert_tokenizer, image_transform, text, image_path, expected_label)\n"
      ],
      "metadata": {
        "id": "VY_dWAwlh9dz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "35b5a633-f3e9-48c4-be36-de6c9c8d6b7a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing entry 248:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted Label: 2016\n",
            "Expected Label: 2016\n",
            "Testing entry 71:\n",
            "Predicted Label: No\n",
            "Expected Label: No\n",
            "Testing entry 253:\n",
            "Predicted Label: 2016\n",
            "Expected Label: 2015\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import requests\n",
        "from io import BytesIO\n",
        "from PIL import Image, UnidentifiedImageError\n",
        "import numpy as np\n",
        "\n",
        "def calculate_metrics(predictions, labels):\n",
        "    # Ensure predictions and labels are numpy arrays for easier handling\n",
        "    predictions = np.array(predictions)\n",
        "    labels = np.array(labels)\n",
        "\n",
        "    # Hit Rate @ 1 (binary correctness)\n",
        "    hit_rate = np.mean([1 if pred == label else 0 for pred, label in zip(predictions, labels)])\n",
        "\n",
        "    # MRR (Mean Reciprocal Rank)\n",
        "    reciprocal_ranks = []\n",
        "    for label, prediction in zip(labels, predictions):\n",
        "        if label in prediction:\n",
        "            rank = np.where(prediction == label)[0][0] + 1\n",
        "            reciprocal_ranks.append(1.0 / rank)\n",
        "        else:\n",
        "            reciprocal_ranks.append(0.0)\n",
        "    mrr = np.mean(reciprocal_ranks)\n",
        "\n",
        "    # Mean Correctness (binary correctness)\n",
        "    mean_correctness = np.mean([1 if pred == label else 0 for pred, label in zip(predictions, labels)])\n",
        "\n",
        "    # Print the metrics\n",
        "    print(\"Evaluation Metrics:\")\n",
        "    print(f\"Hit Rate @ 1: {hit_rate:.4f}\")\n",
        "    print(f\"MRR: {mrr:.4f}\")\n",
        "    print(f\"Mean Correctness: {mean_correctness:.4f}\")\n",
        "\n",
        "def test_single_input(model, tokenizer, image_transform, text, image_path, expected_label):\n",
        "    model.eval()\n",
        "\n",
        "    # Process the text input\n",
        "    text_inputs = tokenizer(text, padding=True, truncation=True, return_tensors='pt').to(device)\n",
        "\n",
        "    try:\n",
        "        # Load and process the image input from local file\n",
        "        image = Image.open(image_path)\n",
        "        if image_transform:\n",
        "            image = image_transform(image).unsqueeze(0).to(device)\n",
        "    except UnidentifiedImageError as e:\n",
        "        print(f\"Error loading image: {e}\")\n",
        "        return None\n",
        "\n",
        "    with torch.no_grad():\n",
        "        text_outputs = model.bert(**text_inputs)\n",
        "        text_embedding = text_outputs.pooler_output\n",
        "        image_embedding = model.resnet(image)\n",
        "        combined = torch.cat((text_embedding, image_embedding), dim=1)\n",
        "        output = model.fc(combined)\n",
        "\n",
        "    _, predicted_label_idx = torch.max(output, 1)\n",
        "    predicted_label = list(label_to_index.keys())[list(label_to_index.values()).index(predicted_label_idx.item())]\n",
        "\n",
        "    return predicted_label\n",
        "\n",
        "# Load processed data\n",
        "processed_data = pd.read_csv('processed_murag_data.csv')\n",
        "\n",
        "predictions = []\n",
        "labels = []\n",
        "\n",
        "# Evaluate all entries in the dataset\n",
        "for idx in range(len(processed_data)):\n",
        "    context = eval(processed_data.iloc[idx]['context'])  # Evaluate the context dictionary\n",
        "    image_path = context['image_path']                  # Extract the image path\n",
        "    text = processed_data.iloc[idx]['question']         # Extract the question\n",
        "    expected_label = processed_data.iloc[idx]['answer'] # Extract the expected answer\n",
        "\n",
        "    # Check if the file exists\n",
        "    if not os.path.isfile(image_path):\n",
        "        print(f\"Image file does not exist: {image_path}\")\n",
        "    else:\n",
        "        # Run the test\n",
        "        predicted_label = test_single_input(model, model.bert_tokenizer, image_transform, text, image_path, expected_label)\n",
        "        if predicted_label is not None:\n",
        "            predictions.append([predicted_label])  # Wrap predicted label in a list\n",
        "            labels.append([expected_label])        # Wrap expected label in a list\n",
        "\n",
        "# Calculate and print the metrics\n",
        "calculate_metrics(predictions, labels)\n"
      ],
      "metadata": {
        "id": "viweBLCIoxz_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3d929ee4-a300-40ae-f7a2-c9566e381a79"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation Metrics:\n",
            "Hit Rate @ 1: 0.8839\n",
            "MRR: 0.8839\n",
            "Mean Correctness: 0.8839\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import random\n",
        "import numpy as np\n",
        "import torch\n",
        "from PIL import Image, UnidentifiedImageError\n",
        "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
        "\n",
        "def calculate_metrics(predictions, labels):\n",
        "    # Ensure predictions and labels are numpy arrays for easier handling\n",
        "    predictions = np.array(predictions)\n",
        "    labels = np.array(labels)\n",
        "\n",
        "    # Hit Rate @ 1 (binary correctness)\n",
        "    hit_rate = np.mean([1 if pred == label else 0 for pred, label in zip(predictions, labels)])\n",
        "\n",
        "    # Mean Correctness (binary correctness)\n",
        "    mean_correctness = np.mean([1 if pred == label else 0 for pred, label in zip(predictions, labels)])\n",
        "\n",
        "    # Print the metrics\n",
        "    print(\"Evaluation Metrics:\")\n",
        "    print(f\"Hit Rate @ 1: {hit_rate:.4f}\")\n",
        "    print(f\"Mean Correctness: {mean_correctness:.4f}\")\n",
        "\n",
        "def test_single_input(model, tokenizer, image_transform, text, image_path):\n",
        "    model.eval()\n",
        "\n",
        "    # Process the text input\n",
        "    text_inputs = tokenizer(text, padding=True, truncation=True, return_tensors='pt').to(device)\n",
        "\n",
        "    try:\n",
        "        # Load and process the image input from local file\n",
        "        image = Image.open(image_path)\n",
        "        if image_transform:\n",
        "            image = image_transform(image).unsqueeze(0).to(device)\n",
        "    except UnidentifiedImageError as e:\n",
        "        print(f\"Error loading image: {e}\")\n",
        "        return None\n",
        "\n",
        "    with torch.no_grad():\n",
        "        text_outputs = model.bert(**text_inputs)\n",
        "        text_embedding = text_outputs.pooler_output\n",
        "        image_embedding = model.resnet(image)\n",
        "        combined = torch.cat((text_embedding, image_embedding), dim=1)\n",
        "        output = model.fc(combined)\n",
        "\n",
        "    _, predicted_label_idx = torch.max(output, 1)\n",
        "    predicted_label = list(label_to_index.keys())[list(label_to_index.values()).index(predicted_label_idx.item())]\n",
        "\n",
        "    return predicted_label\n",
        "\n",
        "# Load processed data\n",
        "processed_data = pd.read_csv('processed_murag_data.csv')\n",
        "\n",
        "# Specify the number of samples to test\n",
        "num_samples = 5  # Change this to your desired sample size\n",
        "\n",
        "# Randomly select entries from the dataset\n",
        "random_indices = random.sample(range(len(processed_data)), num_samples)\n",
        "predictions = []\n",
        "labels = []\n",
        "\n",
        "# Load pre-trained GPT-2 model and tokenizer\n",
        "gpt2_model = GPT2LMHeadModel.from_pretrained('gpt2').to(device)\n",
        "gpt2_tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
        "\n",
        "# Modify the integration function to include attention mask\n",
        "def integrate_with_gpt2(model, gpt2_model, gpt2_tokenizer, image, text_input):\n",
        "    model.eval()\n",
        "    gpt2_model.eval()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        text_inputs = model.bert_tokenizer(text_input, padding=True, truncation=True, return_tensors='pt', return_attention_mask=True).to(device)\n",
        "        text_outputs = model.bert(**text_inputs)\n",
        "        text_embedding = text_outputs.pooler_output\n",
        "\n",
        "        image_embedding = model.resnet(image)\n",
        "        combined = torch.cat((text_embedding, image_embedding), dim=1)\n",
        "\n",
        "    # Generate text using GPT-2\n",
        "    gpt2_input_ids = gpt2_tokenizer.encode(text_input, return_tensors='pt').to(device)\n",
        "    gpt2_outputs = gpt2_model.generate(gpt2_input_ids, max_new_tokens=50, num_return_sequences=1)\n",
        "\n",
        "    generated_text = gpt2_tokenizer.decode(gpt2_outputs[0], skip_special_tokens=True)\n",
        "    return generated_text\n",
        "\n",
        "\n",
        "# Evaluate the selected entries\n",
        "for idx in random_indices:\n",
        "    context = eval(processed_data.iloc[idx]['context'])  # Evaluate the context dictionary\n",
        "    image_path = context['image_path']                  # Extract the image path\n",
        "    text = processed_data.iloc[idx]['question']         # Extract the question\n",
        "    expected_label = processed_data.iloc[idx]['answer'] # Extract the expected answer\n",
        "\n",
        "    # Check if the file exists\n",
        "    if not os.path.isfile(image_path):\n",
        "        print(f\"Image file does not exist: {image_path}\")\n",
        "        continue\n",
        "\n",
        "    # Run the test for prediction\n",
        "    predicted_label = test_single_input(model, model.bert_tokenizer, image_transform, text, image_path)\n",
        "    if predicted_label is not None:\n",
        "        predictions.append(predicted_label)  # Add predicted label\n",
        "        labels.append(expected_label)        # Add expected label\n",
        "\n",
        "    # Load and process the image for GPT-2 integration\n",
        "    image = Image.open(image_path)\n",
        "    if image_transform:\n",
        "        image = image_transform(image).unsqueeze(0).to(device)\n",
        "\n",
        "    # Integrate and generate text with GPT-2\n",
        "    generated_response = integrate_with_gpt2(model, gpt2_model, gpt2_tokenizer, image, text)\n",
        "    print(f\"Question: {text}\")\n",
        "    print(f\"Expected Answer: {expected_label}\")\n",
        "    print(f\"Predicted Label: {predicted_label}\")\n",
        "    print(f\"Generated Response: {generated_response}\")\n",
        "\n",
        "# Calculate and print the metrics\n",
        "calculate_metrics(predictions, labels)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MUmlwUC74ecB",
        "outputId": "2fb5a537-8ffe-48c9-b25a-1f58cbd74630"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: Is this book related to Sports & Outdoors?\n",
            "Expected Answer: No\n",
            "Predicted Label: No\n",
            "Generated Response: Is this book related to Sports & Outdoors?\n",
            "\n",
            "I think it's a good book. It's a good book. It's a good book. It's a good book. It's a good book. It's a good book. It's a good book. It's a good\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: What is the year printed on this calendar?\n",
            "Expected Answer: 2016\n",
            "Predicted Label: 2016\n",
            "Generated Response: What is the year printed on this calendar?\n",
            "\n",
            "The year printed on this calendar is the year of the first printing of the book.\n",
            "\n",
            "The year printed on this calendar is the year of the first printing of the book.\n",
            "\n",
            "The year printed on this calendar is the year of\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: What is the title of this book?\n",
            "Expected Answer: Llewellyn's 2016 Witches' Datebook\n",
            "Predicted Label: Llewellyn's 2016 Witches' Datebook\n",
            "Generated Response: What is the title of this book?\n",
            "\n",
            "The title of this book is \"The Great American Novel.\" It is a book about the American Revolution. It is a book about the American Revolution. It is a book about the American Revolution. It is a book about the American Revolution.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: Which year's calendar is this?\n",
            "Expected Answer: 2016\n",
            "Predicted Label: 2016\n",
            "Generated Response: Which year's calendar is this?\n",
            "\n",
            "The year is 2017.\n",
            "\n",
            "The year is 2018.\n",
            "\n",
            "The year is 2019.\n",
            "\n",
            "The year is 2020.\n",
            "\n",
            "The year is 2021.\n",
            "\n",
            "The year is 2022.\n",
            "\n",
            "The year is 2023.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: Who is the author of this book?\n",
            "Expected Answer: Year-In-A-Box\n",
            "Predicted Label: 2016\n",
            "Generated Response: Who is the author of this book?\n",
            "\n",
            "I am a writer and a writer's assistant. I am a writer's assistant. I am a writer's assistant. I am a writer's assistant. I am a writer's assistant. I am a writer's assistant. I am a\n",
            "Evaluation Metrics:\n",
            "Hit Rate @ 1: 0.8000\n",
            "Mean Correctness: 0.8000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_metrics(train_losses, train_accuracies):\n",
        "    epochs = range(1, len(train_losses) + 1)\n",
        "\n",
        "    plt.figure(figsize=(12, 5))\n",
        "\n",
        "    # Loss Plot\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(epochs, train_losses, label='Training Loss')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.title('Training Loss')\n",
        "    plt.legend()\n",
        "\n",
        "    # Accuracy Plot\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(epochs, train_accuracies, label='Training Accuracy')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.title('Training Accuracy')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "# Simulated loss and accuracy values for demonstration\n",
        "train_losses = [3.9869, 2.5093, 1.7222, 1.3020, 0.9642]\n",
        "train_accuracies = [0.07, 0.48, 0.65, 0.73, 0.81]\n",
        "\n",
        "plot_metrics(train_losses, train_accuracies)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "id": "r0rlYIGxN_IH",
        "outputId": "0f32e38d-03d4-4e83-85e9-fa5af5661ed9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x500 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 1. Visualizing Hit Rate and Mean Correctness\n",
        "def visualize_hit_rate_mean_correctness(hit_rate, mean_correctness, mrr):\n",
        "    metrics = ['Hit Rate @ 1', 'Mean Correctness', 'MRR']\n",
        "    values = [hit_rate, mean_correctness, mrr]\n",
        "\n",
        "    plt.figure(figsize=(6, 4))\n",
        "    plt.bar(metrics, values, color=['skyblue', 'lightcoral'])\n",
        "    plt.title('Hit Rate @ 1 & Mean Correctness & MRR')\n",
        "    plt.ylabel('Score')\n",
        "    plt.ylim([0, 1])\n",
        "    plt.show()\n",
        "\n",
        "hit_rate= 0.8839\n",
        "mrr=0.8839\n",
        "mean_correctness= 0.8839\n",
        "\n",
        "# 1. Plot Hit Rate and Mean Correctness\n",
        "visualize_hit_rate_mean_correctness(hit_rate, mean_correctness, mrr)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "id": "6g5YVTLeT-5S",
        "outputId": "3462405e-4fc9-4a44-bbaa-79ce9e83e8be"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 600x400 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SjF8jkQsVJpu"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "e203260fc47e49eca3733a57f4e6fd1b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_180940aadbc64881809755cc53f1172e",
              "IPY_MODEL_f165a8f17a5144a4b651ca032aa27d71",
              "IPY_MODEL_9e5235714f2d40dea6d45349458ad64d"
            ],
            "layout": "IPY_MODEL_47af4892314546d1bdaf38154525126f"
          }
        },
        "180940aadbc64881809755cc53f1172e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_56bb7b3e8fa142ff8470ca92e4e6c4da",
            "placeholder": "​",
            "style": "IPY_MODEL_ad87482fd7834e049c8aa4c61a67d2ed",
            "value": "config.json: 100%"
          }
        },
        "f165a8f17a5144a4b651ca032aa27d71": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f68c4bec937648958b624bde6bddb97e",
            "max": 570,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_bfde078ebee84a54826a9f95955cddb4",
            "value": 570
          }
        },
        "9e5235714f2d40dea6d45349458ad64d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3cada9fc296c4fb1b3d7018f8cd09f73",
            "placeholder": "​",
            "style": "IPY_MODEL_4714cc5be8c44d71b6bcd319e70842b8",
            "value": " 570/570 [00:00&lt;00:00, 3.21kB/s]"
          }
        },
        "47af4892314546d1bdaf38154525126f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "56bb7b3e8fa142ff8470ca92e4e6c4da": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ad87482fd7834e049c8aa4c61a67d2ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f68c4bec937648958b624bde6bddb97e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bfde078ebee84a54826a9f95955cddb4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3cada9fc296c4fb1b3d7018f8cd09f73": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4714cc5be8c44d71b6bcd319e70842b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "44fcedaba19640798539feed184d367a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2e93a603b98544099287da10bc9de01b",
              "IPY_MODEL_bbe56034fdb6400289bd3e9c9ae5a71f",
              "IPY_MODEL_186caa299e6e4562995495d064bef8e1"
            ],
            "layout": "IPY_MODEL_c094d315277e4d8daea93ee5260b3e74"
          }
        },
        "2e93a603b98544099287da10bc9de01b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ad0b2614d7774172823187efa3745cb8",
            "placeholder": "​",
            "style": "IPY_MODEL_4cd27ca693204d6798bca7a8ac76013c",
            "value": "model.safetensors: 100%"
          }
        },
        "bbe56034fdb6400289bd3e9c9ae5a71f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c318708c6e364d2badb6f7fc109ba6f4",
            "max": 440449768,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_97e87c14ffc142d4b12e431fe33514f4",
            "value": 440449768
          }
        },
        "186caa299e6e4562995495d064bef8e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f3f1536b628d486c8bbf6c84a3e2497c",
            "placeholder": "​",
            "style": "IPY_MODEL_e60b77666f95412d94ad516d11a08c97",
            "value": " 440M/440M [00:11&lt;00:00, 43.9MB/s]"
          }
        },
        "c094d315277e4d8daea93ee5260b3e74": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ad0b2614d7774172823187efa3745cb8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4cd27ca693204d6798bca7a8ac76013c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c318708c6e364d2badb6f7fc109ba6f4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "97e87c14ffc142d4b12e431fe33514f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f3f1536b628d486c8bbf6c84a3e2497c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e60b77666f95412d94ad516d11a08c97": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ecc4f94e49b545ea8bc0962019cfb8fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_421718a167b14c3398079b9f542fcee3",
              "IPY_MODEL_b3c9e9a50acb48c18623eb2ebb4b1672",
              "IPY_MODEL_02c95a4c36e54061b54f8b49a7987070"
            ],
            "layout": "IPY_MODEL_4ee2dce619d0481783ca0296c67b1071"
          }
        },
        "421718a167b14c3398079b9f542fcee3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_999d96d7964a44259ea82383227e1546",
            "placeholder": "​",
            "style": "IPY_MODEL_009e08782ade4e90a9d7a3ded4925481",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "b3c9e9a50acb48c18623eb2ebb4b1672": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_92320eb340ba4ed18bc0c177d0bb1fd8",
            "max": 48,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_dada0ecf97ef4865bdd6422842fc8385",
            "value": 48
          }
        },
        "02c95a4c36e54061b54f8b49a7987070": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_973ca71cc43547889c65a681c9ada8de",
            "placeholder": "​",
            "style": "IPY_MODEL_113983b49f3241d7a0d254893b0560bb",
            "value": " 48.0/48.0 [00:00&lt;00:00, 471B/s]"
          }
        },
        "4ee2dce619d0481783ca0296c67b1071": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "999d96d7964a44259ea82383227e1546": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "009e08782ade4e90a9d7a3ded4925481": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "92320eb340ba4ed18bc0c177d0bb1fd8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dada0ecf97ef4865bdd6422842fc8385": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "973ca71cc43547889c65a681c9ada8de": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "113983b49f3241d7a0d254893b0560bb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "64c6d0307cde4d4890345ce1ac1928c1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_40d675faae9c4653b78e23c799fd14db",
              "IPY_MODEL_40b723bb58e14dc68cb3dd0ac1385e2d",
              "IPY_MODEL_ed02039f37524c7f92d67adc1fbb53b1"
            ],
            "layout": "IPY_MODEL_bd096a5ae334404f8aefea7d92dc1b8d"
          }
        },
        "40d675faae9c4653b78e23c799fd14db": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e00f12b95a554a7cb222f861cd429c50",
            "placeholder": "​",
            "style": "IPY_MODEL_b0af37fb10484dadbe47ead6cd112fc6",
            "value": "vocab.txt: 100%"
          }
        },
        "40b723bb58e14dc68cb3dd0ac1385e2d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_65639109df474af89213b3e012736c92",
            "max": 231508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_361d2592c61e4e05b79db432cbabf7f5",
            "value": 231508
          }
        },
        "ed02039f37524c7f92d67adc1fbb53b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6a187c4c5999461a9c653b93c886fb39",
            "placeholder": "​",
            "style": "IPY_MODEL_a0a77afac2f94af4b68fdebaf3ea4384",
            "value": " 232k/232k [00:00&lt;00:00, 1.57MB/s]"
          }
        },
        "bd096a5ae334404f8aefea7d92dc1b8d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e00f12b95a554a7cb222f861cd429c50": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b0af37fb10484dadbe47ead6cd112fc6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "65639109df474af89213b3e012736c92": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "361d2592c61e4e05b79db432cbabf7f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6a187c4c5999461a9c653b93c886fb39": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a0a77afac2f94af4b68fdebaf3ea4384": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4fb22149260b400fb05b5c25052c3436": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_27388f8bf3a9431f9a3673bc54d55141",
              "IPY_MODEL_c454214fcb224f30b23920508405f479",
              "IPY_MODEL_879a03e9ab4e4231809a53fc85e329fd"
            ],
            "layout": "IPY_MODEL_6eccd9c499bc4051a8ef8fb3b994516f"
          }
        },
        "27388f8bf3a9431f9a3673bc54d55141": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_36cea72c31fb4f21a45803dfd02fe72f",
            "placeholder": "​",
            "style": "IPY_MODEL_f0a2ca80c055490f9e236df0a2b310a9",
            "value": "tokenizer.json: 100%"
          }
        },
        "c454214fcb224f30b23920508405f479": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9db839401e294707b1e9d40425faac1f",
            "max": 466062,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b9f2c0ce70364560b25e89c934d5df3d",
            "value": 466062
          }
        },
        "879a03e9ab4e4231809a53fc85e329fd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_56342c30de844e5fa9dd97e419e32097",
            "placeholder": "​",
            "style": "IPY_MODEL_7dedc6905ee247b7b3404741fad5b1ba",
            "value": " 466k/466k [00:00&lt;00:00, 1.96MB/s]"
          }
        },
        "6eccd9c499bc4051a8ef8fb3b994516f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "36cea72c31fb4f21a45803dfd02fe72f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f0a2ca80c055490f9e236df0a2b310a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9db839401e294707b1e9d40425faac1f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b9f2c0ce70364560b25e89c934d5df3d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "56342c30de844e5fa9dd97e419e32097": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7dedc6905ee247b7b3404741fad5b1ba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}